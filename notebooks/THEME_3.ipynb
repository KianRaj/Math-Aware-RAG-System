{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file {pdf_path} exists.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "pdf_path = \"Diffusion_Models.pdf\"\n",
    "if not os.path.exists(pdf_path):\n",
    "  url = \"https://arxiv.org/pdf/2208.11970\"\n",
    "  filename = pdf_path\n",
    "  response = requests.get(url)\n",
    "  if response.status_code == 200:\n",
    "    with open(filename, 'wb') as f:\n",
    "      f.write(response.content)\n",
    "  else:\n",
    "    print(f\"Failed to download the file. Status code: {response.status_code}\")\n",
    "else:\n",
    "  print(\"file {pdf_path} exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/data_dump/conda/miniconda3/envs/SARAL/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "23it [00:00, 145.17it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'page_number': 0,\n",
       "  'page_char_count': 2500,\n",
       "  'page_word_count': 469,\n",
       "  'page_sentence_count_raw': 469,\n",
       "  'page_token_count': 625.0,\n",
       "  'text': 'Understanding Diﬀusion Models: A Uniﬁed PerspectiveCalvin LuoGoogle Research, Brain Teamcalvinluo@google.comAugust 26, 2022ContentsIntroduction: Generative Models . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .1Background: ELBO, VAE, and Hierarchical VAE . . . . . . . . . . . . . . . . . . . . . . . .2Evidence Lower Bound . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .2Variational Autoencoders . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .4Hierarchical Variational Autoencoders . . . . . . . . . . . . . . . . . . . . . . . . . . . . .5Variational Diﬀusion Models . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .6Learning Diﬀusion Noise Parameters . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .14Three Equivalent Interpretations. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .15Score-based Generative Models. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .17Guidance. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .20Classiﬁer Guidance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .21Classiﬁer-Free Guidance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .21Closing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .22Introduction: Generative ModelsGiven observed samples x from a distribution of interest, the goal of a generative model is to learn tomodel its true data distribution p(x). Once learned, we can generate new samples from our approximatemodel at will. Furthermore, under some formulations, we are able to use the learned model to evaluate thelikelihood of observed or sampled data as well.There are several well-known directions in current literature, that we will only introduce brieﬂy at a high level.Generative Adversarial Networks (GANs) model the sampling procedure of a complex distribution, whichis learned in an adversarial manner. Another class of generative models, termed \"likelihood-based\", seeksto learn a model that assigns a high likelihood to the observed data samples. This includes autoregressivemodels, normalizing ﬂows, and Variational Autoencoders (VAEs). Another similar approach is energy-basedmodeling, in which a distribution is learned as an arbitrarily ﬂexible energy function that is then normalized.1arXiv:2208.11970v1  [cs.LG]  25 Aug 2022'},\n",
       " {'page_number': 1,\n",
       "  'page_char_count': 3828,\n",
       "  'page_word_count': 13,\n",
       "  'page_sentence_count_raw': 13,\n",
       "  'page_token_count': 957.0,\n",
       "  'text': 'Score-based generative models are highly related; instead of learning to model the energy function itself, theylearn the score of the energy-based model as a neural network. In this work we explore and review diﬀusionmodels, which as we will demonstrate, have both likelihood-based and score-based interpretations.Weshowcase the math behind such models in excruciating detail, with the aim that anyone can follow alongand understand what diﬀusion models are and how they work.Background: ELBO, VAE, and Hierarchical VAEFor many modalities, we can think of the data we observe as represented or generated by an associatedunseen latent variable, which we can denote by random variable z. The best intuition for expressing thisidea is through Plato’s Allegory of the Cave. In the allegory, a group of people are chained inside a cave theirentire life and can only see the two-dimensional shadows projected onto a wall in front of them, which aregenerated by unseen three-dimensional objects passed before a ﬁre. To such people, everything they observeis actually determined by higher-dimensional abstract concepts that they can never behold.Analogously, the objects that we encounter in the actual world may also be generated as a function ofsome higher-level representations; for example, such representations may encapsulate abstract propertiessuch as color, size, shape, and more. Then, what we observe can be interpreted as a three-dimensionalprojection or instantiation of such abstract concepts, just as what the cave people observe is actually atwo-dimensional projection of three-dimensional objects. Whereas the cave people can never see (or evenfully comprehend) the hidden objects, they can still reason and draw inferences about them; in a similarway, we can approximate latent representations that describe the data we observe.Whereas Plato’s Allegory illustrates the idea behind latent variables as potentially unobservable representa-tions that determine observations, a caveat of this analogy is that in generative modeling, we generally seekto learn lower-dimensional latent representations rather than higher-dimensional ones. This is because try-ing to learn a representation of higher dimension than the observation is a fruitless endeavor without strongpriors. On the other hand, learning lower-dimensional latents can also be seen as a form of compression, andcan potentially uncover semantically meaningful structure describing observations.Evidence Lower BoundMathematically, we can imagine the latent variables and the data we observe as modeled by a joint distribu-tion p(x, z). Recall one approach of generative modeling, termed \"likelihood-based\", is to learn a model tomaximize the likelihood p(x) of all observed x. There are two ways we can manipulate this joint distribu-tion to recover the likelihood of purely our observed data p(x); we can explicitly marginalize out the latentvariable z:p(x) =Zp(x, z)dz(1)or, we could also appeal to the chain rule of probability:p(x) = p(x, z)p(z|x)(2)Directly computing and maximizing the likelihood p(x) is diﬃcult because it either involves integrating outall latent variables z in Equation 1, which is intractable for complex models, or it involves having access to aground truth latent encoder p(z|x) in Equation 2. However, using these two equations, we can derive a termcalled the Evidence Lower Bound (ELBO), which as its name suggests, is a lower bound of the evidence.The evidence is quantiﬁed in this case as the log likelihood of the observed data. Then, maximizing theELBO becomes a proxy objective with which to optimize a latent variable model; in the best case, when theELBO is powerfully parameterized and perfectly optimized, it becomes exactly equivalent to the evidence.Formally, the equation of the ELBO is:Eqφ(z|x)\\x14log p(x, z)qφ(z|x)\\x15(3)2'}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import fitz\n",
    "from tqdm.auto import tqdm\n",
    "def text_formatter(text: str)-> str:\n",
    "  cleaned_text = text.replace(\"\\n\",\"\").strip()\n",
    "  return cleaned_text\n",
    "def open_and_read_pdf(pdf_path: str)-> list[dict]:\n",
    "  doc = fitz.open(pdf_path)\n",
    "  pages_and_texts = []\n",
    "  for page_number,page in tqdm(enumerate(doc)):\n",
    "    text = page.get_text()\n",
    "    text = text_formatter(text)\n",
    "    pages_and_texts.append({\"page_number\": page_number ,\n",
    "                            \"page_char_count\": len(text),\n",
    "                            \"page_word_count\": len(text.split(\". \")),\n",
    "                            \"page_sentence_count_raw\": len(text.split(\". \")),\n",
    "                            \"page_token_count\": len(text)/4,\n",
    "                            \"text\":text})\n",
    "  return pages_and_texts\n",
    "pages_and_texts = open_and_read_pdf(pdf_path=pdf_path)\n",
    "pages_and_texts[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>page_char_count</th>\n",
       "      <th>page_word_count</th>\n",
       "      <th>page_sentence_count_raw</th>\n",
       "      <th>page_token_count</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2500</td>\n",
       "      <td>469</td>\n",
       "      <td>469</td>\n",
       "      <td>625.00</td>\n",
       "      <td>Understanding Diﬀusion Models: A Uniﬁed Perspe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3828</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>957.00</td>\n",
       "      <td>Score-based generative models are highly relat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2955</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>738.75</td>\n",
       "      <td>To make the relationship with the evidence exp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3418</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>854.50</td>\n",
       "      <td>Figure 1: A Variational Autoencoder graphicall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3788</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>947.00</td>\n",
       "      <td>A deﬁning feature of the VAE is how the ELBO i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   page_number  page_char_count  page_word_count  page_sentence_count_raw  \\\n",
       "0            0             2500              469                      469   \n",
       "1            1             3828               13                       13   \n",
       "2            2             2955                6                        6   \n",
       "3            3             3418               13                       13   \n",
       "4            4             3788               14                       14   \n",
       "\n",
       "   page_token_count                                               text  \n",
       "0            625.00  Understanding Diﬀusion Models: A Uniﬁed Perspe...  \n",
       "1            957.00  Score-based generative models are highly relat...  \n",
       "2            738.75  To make the relationship with the evidence exp...  \n",
       "3            854.50  Figure 1: A Variational Autoencoder graphicall...  \n",
       "4            947.00  A deﬁning feature of the VAE is how the ELBO i...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(pages_and_texts)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>page_char_count</th>\n",
       "      <th>page_word_count</th>\n",
       "      <th>page_sentence_count_raw</th>\n",
       "      <th>page_token_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>23.00</td>\n",
       "      <td>23.00</td>\n",
       "      <td>23.00</td>\n",
       "      <td>23.00</td>\n",
       "      <td>23.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>11.00</td>\n",
       "      <td>2912.52</td>\n",
       "      <td>30.91</td>\n",
       "      <td>30.91</td>\n",
       "      <td>728.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.78</td>\n",
       "      <td>779.60</td>\n",
       "      <td>95.78</td>\n",
       "      <td>95.78</td>\n",
       "      <td>194.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1702.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>425.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.50</td>\n",
       "      <td>2297.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>574.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>11.00</td>\n",
       "      <td>2808.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>702.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>16.50</td>\n",
       "      <td>3426.50</td>\n",
       "      <td>13.00</td>\n",
       "      <td>13.00</td>\n",
       "      <td>856.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>22.00</td>\n",
       "      <td>4414.00</td>\n",
       "      <td>469.00</td>\n",
       "      <td>469.00</td>\n",
       "      <td>1103.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       page_number  page_char_count  page_word_count  page_sentence_count_raw  \\\n",
       "count        23.00            23.00            23.00                    23.00   \n",
       "mean         11.00          2912.52            30.91                    30.91   \n",
       "std           6.78           779.60            95.78                    95.78   \n",
       "min           0.00          1702.00             3.00                     3.00   \n",
       "25%           5.50          2297.00             7.00                     7.00   \n",
       "50%          11.00          2808.00            10.00                    10.00   \n",
       "75%          16.50          3426.50            13.00                    13.00   \n",
       "max          22.00          4414.00           469.00                   469.00   \n",
       "\n",
       "       page_token_count  \n",
       "count             23.00  \n",
       "mean             728.13  \n",
       "std              194.90  \n",
       "min              425.50  \n",
       "25%              574.25  \n",
       "50%              702.00  \n",
       "75%              856.62  \n",
       "max             1103.50  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df.describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You may need to install spaCy and its English model first:\n",
    "# pip install -U spacy\n",
    "# python -m spacy download en_core_web_sm\n",
    "\n",
    "import spacy\n",
    "from spacy.lang.en import English\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[This is a sentence., This another sentence.]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's use spaCy to break our text into sentences since it's likely a bit more robust than just using text.split(\".\")\n",
    "\n",
    "from spacy.lang.en import English # see https://spacy.io/usage for install instructions\n",
    "\n",
    "nlp = English()\n",
    "\n",
    "# Add a sentencizer pipeline, see https://spacy.io/api/sentencizer/\n",
    "nlp.add_pipe(\"sentencizer\")\n",
    "\n",
    "# Create a document instance as an example\n",
    "doc = nlp(\"This is a sentence. This another sentence.\")\n",
    "assert len(list(doc.sents)) == 2\n",
    "\n",
    "# Access the sentences of the document\n",
    "list(doc.sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:00<00:00, 133.28it/s]\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'pages_and_texts' is a list of dictionaries and 'nlp' is the spaCy model from the previous cell\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "for item in tqdm(pages_and_texts):\n",
    "    item[\"sentences\"] = list(nlp(item[\"text\"]).sents)\n",
    "\n",
    "    # Make sure all sentences are strings\n",
    "    item[\"sentences\"] = [str(sentence) for sentence in item[\"sentences\"]]\n",
    "\n",
    "    # Count the sentences\n",
    "    item[\"page_sentence_count_spacy\"] = len(item[\"sentences\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:00<00:00, 141866.16it/s]\n"
     ]
    }
   ],
   "source": [
    "# To split our groups of sentences into chunks of 10 or less, let's create a function which accepts a list as input and recursively breaks into\n",
    "# down into sublists of a specified size.\n",
    "\n",
    "# Define split size to turn groups of sentences into chunks\n",
    "num_sentence_chunk_size = 10\n",
    "\n",
    "# Create a function that recursively splits a list into desired sizes\n",
    "def split_list(input_list: list,\n",
    "               slice_size: int) -> list[list[str]]:\n",
    "    \"\"\"\n",
    "    Splits the input_list into sublists of size slice_size (or as close as possible).\n",
    "\n",
    "    For example, a list of 17 sentences would be split into two lists of [[10], [7]]\n",
    "    \"\"\"\n",
    "    return [input_list[i:i + slice_size] for i in range(0, len(input_list), slice_size)]\n",
    "\n",
    "# Loop through pages and texts and split sentences into chunks\n",
    "for item in tqdm(pages_and_texts):\n",
    "    item[\"sentence_chunks\"] = split_list(input_list=item[\"sentences\"],\n",
    "                                         slice_size=num_sentence_chunk_size)\n",
    "    item[\"num_chunks\"] = len(item[\"sentence_chunks\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'page_number': 11,\n",
       "  'page_char_count': 2728,\n",
       "  'page_word_count': 6,\n",
       "  'page_sentence_count_raw': 6,\n",
       "  'page_token_count': 682.0,\n",
       "  'text': 'We have therefore derived the Gaussian form of q(xt|x0). This derivation can be modiﬁed to also yield theGaussian parameterization describing q(xt−1|x0). Now, knowing the forms of both q(xt|x0) and q(xt−1|x0),we can proceed to calculate the form of q(xt−1|xt, x0) by substituting into the Bayes rule expansion:q(xt−1|xt, x0) = q(xt|xt−1, x0)q(xt−1|x0)q(xt|x0)(71)= N(xt; √αtxt−1, (1 −αt)I)N(xt−1; √¯αt−1x0, (1 −¯αt−1)I)N(xt; √¯αtx0, (1 −¯αt)I)(72)∝exp\\x1a−\\x14(xt −√αtxt−1)22(1 −αt)+ (xt−1 −√¯αt−1x0)22(1 −¯αt−1)−(xt −√¯αtx0)22(1 −¯αt)\\x15\\x1b(73)= exp\\x1a−12\\x14(xt −√αtxt−1)21 −αt+ (xt−1 −√¯αt−1x0)21 −¯αt−1−(xt −√¯αtx0)21 −¯αt\\x15\\x1b(74)= exp\\x1a−12\\x14(−2√αtxtxt−1 + αtx2t−1)1 −αt+ (x2t−1 −2√¯αt−1xt−1x0)1 −¯αt−1+ C(xt, x0)\\x15\\x1b(75)∝exp\\x1a−12\\x14−2√αtxtxt−11 −αt+ αtx2t−11 −αt+x2t−11 −¯αt−1−2√¯αt−1xt−1x01 −¯αt−1\\x15\\x1b(76)= exp\\x1a−12\\x14(αt1 −αt+11 −¯αt−1)x2t−1 −2\\x12√αtxt1 −αt+√¯αt−1x01 −¯αt−1\\x13xt−1\\x15\\x1b(77)= exp\\x1a−12\\x14αt(1 −¯αt−1) + 1 −αt(1 −αt)(1 −¯αt−1)x2t−1 −2\\x12√αtxt1 −αt+√¯αt−1x01 −¯αt−1\\x13xt−1\\x15\\x1b(78)= exp\\x1a−12\\x14 αt −¯αt + 1 −αt(1 −αt)(1 −¯αt−1)x2t−1 −2\\x12√αtxt1 −αt+√¯αt−1x01 −¯αt−1\\x13xt−1\\x15\\x1b(79)= exp\\x1a−12\\x141 −¯αt(1 −αt)(1 −¯αt−1)x2t−1 −2\\x12√αtxt1 −αt+√¯αt−1x01 −¯αt−1\\x13xt−1\\x15\\x1b(80)= exp\\uf8f1\\uf8f2\\uf8f3−12\\x121 −¯αt(1 −αt)(1 −¯αt−1)\\x13 \\uf8ee\\uf8f0x2t−1 −2\\x10 √αtxt1−αt +√¯αt−1x01−¯αt−1\\x111−¯αt(1−αt)(1−¯αt−1)xt−1\\uf8f9\\uf8fb\\uf8fc\\uf8fd\\uf8fe(81)= exp\\uf8f1\\uf8f2\\uf8f3−12\\x121 −¯αt(1 −αt)(1 −¯αt−1)\\x13 \\uf8ee\\uf8f0x2t−1 −2\\x10 √αtxt1−αt +√¯αt−1x01−¯αt−1\\x11(1 −αt)(1 −¯αt−1)1 −¯αtxt−1\\uf8f9\\uf8fb\\uf8fc\\uf8fd\\uf8fe(82)= exp(−12 1(1−αt)(1−¯αt−1)1−¯αt! \\x14x2t−1 −2√αt(1 −¯αt−1)xt + √¯αt−1(1 −αt)x01 −¯αtxt−1\\x15)(83)∝N(xt−1;√αt(1 −¯αt−1)xt + √¯αt−1(1 −αt)x01 −¯αt|{z}µq(xt,x0), (1 −αt)(1 −¯αt−1)1 −¯αtI|{z}Σq(t))(84)where in Equation 75, C(xt, x0) is a constant term with respect to xt−1 computed as a combination of onlyxt, x0, and α values; this term is implicitly returned in Equation 84 to complete the square.We have therefore shown that at each step, xt−1 ∼q(xt−1|xt, x0) is normally distributed, with meanµq(xt, x0) that is a function of xt and x0, and variance Σq(t) as a function of α coeﬃcients.Theseα coeﬃcients are known and ﬁxed at each timestep; they are either set permanently when modeled ashyperparameters, or treated as the current inference output of a network that seeks to model them. FollowingEquation 84, we can rewrite our variance equation as Σq(t) = σ2q(t)I, where:σ2q(t) = (1 −αt)(1 −¯αt−1)1 −¯αt(85)In order to match approximate denoising transition step pθ(xt−1|xt) to ground-truth denoising transitionstep q(xt−1|xt, x0) as closely as possible, we can also model it as a Gaussian. Furthermore, as all α termsare known to be frozen at each timestep, we can immediately construct the variance of the approximatedenoising transition step to also be Σq(t) = σ2q(t)I. We must parameterize its mean µθ(xt, t) as a functionof xt, however, since pθ(xt−1|xt) does not condition on x0.12',\n",
       "  'sentences': ['We have therefore derived the Gaussian form of q(xt|x0).',\n",
       "   'This derivation can be modiﬁed to also yield theGaussian parameterization describing q(xt−1|x0).',\n",
       "   'Now, knowing the forms of both q(xt|x0) and q(xt−1|x0),we can proceed to calculate the form of q(xt−1|xt, x0) by substituting into the Bayes rule expansion:q(xt−1|xt, x0) = q(xt|xt−1, x0)q(xt−1|x0)q(xt|x0)(71)= N(xt; √αtxt−1, (1 −αt)I)N(xt−1; √¯αt−1x0, (1 −¯αt−1)I)N(xt; √¯αtx0, (1 −¯αt)I)(72)∝exp\\x1a−\\x14(xt −√αtxt−1)22(1 −αt)+ (xt−1 −√¯αt−1x0)22(1 −¯αt−1)−(xt −√¯αtx0)22(1 −¯αt)\\x15\\x1b(73)= exp\\x1a−12\\x14(xt −√αtxt−1)21 −αt+ (xt−1 −√¯αt−1x0)21 −¯αt−1−(xt −√¯αtx0)21 −¯αt\\x15\\x1b(74)= exp\\x1a−12\\x14(−2√αtxtxt−1 + αtx2t−1)1 −αt+ (x2t−1 −2√¯αt−1xt−1x0)1 −¯αt−1+ C(xt, x0)\\x15\\x1b(75)∝exp\\x1a−12\\x14−2√αtxtxt−11 −αt+ αtx2t−11 −αt+x2t−11 −¯αt−1−2√¯αt−1xt−1x01 −¯αt−1\\x15\\x1b(76)= exp\\x1a−12\\x14(αt1 −αt+11 −¯αt−1)x2t−1 −2\\x12√αtxt1 −αt+√¯αt−1x01 −¯αt−1\\x13xt−1\\x15\\x1b(77)= exp\\x1a−12\\x14αt(1 −¯αt−1) + 1 −αt(1 −αt)(1 −¯αt−1)x2t−1 −2\\x12√αtxt1 −αt+√¯αt−1x01 −¯αt−1\\x13xt−1\\x15\\x1b(78)= exp\\x1a−12\\x14 αt −¯αt + 1 −αt(1 −αt)(1 −¯αt−1)x2t−1 −2\\x12√αtxt1 −αt+√¯αt−1x01 −¯αt−1\\x13xt−1\\x15\\x1b(79)= exp\\x1a−12\\x141 −¯αt(1 −αt)(1 −¯αt−1)x2t−1 −2\\x12√αtxt1 −αt+√¯αt−1x01 −¯αt−1\\x13xt−1\\x15\\x1b(80)= exp\\uf8f1\\uf8f2\\uf8f3−12\\x121 −¯αt(1 −αt)(1 −¯αt−1)\\x13 \\uf8ee\\uf8f0x2t−1 −2\\x10 √αtxt1−αt +√¯αt−1x01−¯αt−1\\x111−¯αt(1−αt)(1−¯αt−1)xt−1\\uf8f9\\uf8fb\\uf8fc\\uf8fd\\uf8fe(81)= exp\\uf8f1\\uf8f2\\uf8f3−12\\x121 −¯αt(1 −αt)(1 −¯αt−1)\\x13 \\uf8ee\\uf8f0x2t−1 −2\\x10 √αtxt1−αt +√¯αt−1x01−¯αt−1\\x11(1 −αt)(1 −¯αt−1)1 −¯αtxt−1\\uf8f9\\uf8fb\\uf8fc\\uf8fd\\uf8fe(82)= exp(−12 1(1−αt)(1−¯αt−1)1−¯αt!',\n",
       "   '\\x14x2t−1 −2√αt(1 −¯αt−1)xt + √¯αt−1(1 −αt)x01 −¯αtxt−1\\x15)(83)∝N(xt−1;√αt(1 −¯αt−1)xt + √¯αt−1(1 −αt)x01 −¯αt|{z}µq(xt,x0), (1 −αt)(1 −¯αt−1)1 −¯αtI|{z}Σq(t))(84)where in Equation 75, C(xt, x0) is a constant term with respect to xt−1 computed as a combination of onlyxt, x0, and α values; this term is implicitly returned in Equation 84 to complete the square.',\n",
       "   'We have therefore shown that at each step, xt−1 ∼q(xt−1|xt, x0) is normally distributed, with meanµq(xt, x0) that is a function of xt and x0, and variance Σq(t) as a function of α coeﬃcients.',\n",
       "   'Theseα coeﬃcients are known and ﬁxed at each timestep; they are either set permanently when modeled ashyperparameters, or treated as the current inference output of a network that seeks to model them.',\n",
       "   'FollowingEquation 84, we can rewrite our variance equation as Σq(t) = σ2q(t)I, where:σ2q(t) = (1 −αt)(1 −¯αt−1)1 −¯αt(85)In order to match approximate denoising transition step pθ(xt−1|xt) to ground-truth denoising transitionstep q(xt−1|xt, x0) as closely as possible, we can also model it as a Gaussian.',\n",
       "   'Furthermore, as all α termsare known to be frozen at each timestep, we can immediately construct the variance of the approximatedenoising transition step to also be Σq(t) = σ2q(t)I. We must parameterize its mean µθ(xt, t) as a functionof xt, however, since pθ(xt−1|xt) does not condition on x0.12'],\n",
       "  'page_sentence_count_spacy': 8,\n",
       "  'sentence_chunks': [['We have therefore derived the Gaussian form of q(xt|x0).',\n",
       "    'This derivation can be modiﬁed to also yield theGaussian parameterization describing q(xt−1|x0).',\n",
       "    'Now, knowing the forms of both q(xt|x0) and q(xt−1|x0),we can proceed to calculate the form of q(xt−1|xt, x0) by substituting into the Bayes rule expansion:q(xt−1|xt, x0) = q(xt|xt−1, x0)q(xt−1|x0)q(xt|x0)(71)= N(xt; √αtxt−1, (1 −αt)I)N(xt−1; √¯αt−1x0, (1 −¯αt−1)I)N(xt; √¯αtx0, (1 −¯αt)I)(72)∝exp\\x1a−\\x14(xt −√αtxt−1)22(1 −αt)+ (xt−1 −√¯αt−1x0)22(1 −¯αt−1)−(xt −√¯αtx0)22(1 −¯αt)\\x15\\x1b(73)= exp\\x1a−12\\x14(xt −√αtxt−1)21 −αt+ (xt−1 −√¯αt−1x0)21 −¯αt−1−(xt −√¯αtx0)21 −¯αt\\x15\\x1b(74)= exp\\x1a−12\\x14(−2√αtxtxt−1 + αtx2t−1)1 −αt+ (x2t−1 −2√¯αt−1xt−1x0)1 −¯αt−1+ C(xt, x0)\\x15\\x1b(75)∝exp\\x1a−12\\x14−2√αtxtxt−11 −αt+ αtx2t−11 −αt+x2t−11 −¯αt−1−2√¯αt−1xt−1x01 −¯αt−1\\x15\\x1b(76)= exp\\x1a−12\\x14(αt1 −αt+11 −¯αt−1)x2t−1 −2\\x12√αtxt1 −αt+√¯αt−1x01 −¯αt−1\\x13xt−1\\x15\\x1b(77)= exp\\x1a−12\\x14αt(1 −¯αt−1) + 1 −αt(1 −αt)(1 −¯αt−1)x2t−1 −2\\x12√αtxt1 −αt+√¯αt−1x01 −¯αt−1\\x13xt−1\\x15\\x1b(78)= exp\\x1a−12\\x14 αt −¯αt + 1 −αt(1 −αt)(1 −¯αt−1)x2t−1 −2\\x12√αtxt1 −αt+√¯αt−1x01 −¯αt−1\\x13xt−1\\x15\\x1b(79)= exp\\x1a−12\\x141 −¯αt(1 −αt)(1 −¯αt−1)x2t−1 −2\\x12√αtxt1 −αt+√¯αt−1x01 −¯αt−1\\x13xt−1\\x15\\x1b(80)= exp\\uf8f1\\uf8f2\\uf8f3−12\\x121 −¯αt(1 −αt)(1 −¯αt−1)\\x13 \\uf8ee\\uf8f0x2t−1 −2\\x10 √αtxt1−αt +√¯αt−1x01−¯αt−1\\x111−¯αt(1−αt)(1−¯αt−1)xt−1\\uf8f9\\uf8fb\\uf8fc\\uf8fd\\uf8fe(81)= exp\\uf8f1\\uf8f2\\uf8f3−12\\x121 −¯αt(1 −αt)(1 −¯αt−1)\\x13 \\uf8ee\\uf8f0x2t−1 −2\\x10 √αtxt1−αt +√¯αt−1x01−¯αt−1\\x11(1 −αt)(1 −¯αt−1)1 −¯αtxt−1\\uf8f9\\uf8fb\\uf8fc\\uf8fd\\uf8fe(82)= exp(−12 1(1−αt)(1−¯αt−1)1−¯αt!',\n",
       "    '\\x14x2t−1 −2√αt(1 −¯αt−1)xt + √¯αt−1(1 −αt)x01 −¯αtxt−1\\x15)(83)∝N(xt−1;√αt(1 −¯αt−1)xt + √¯αt−1(1 −αt)x01 −¯αt|{z}µq(xt,x0), (1 −αt)(1 −¯αt−1)1 −¯αtI|{z}Σq(t))(84)where in Equation 75, C(xt, x0) is a constant term with respect to xt−1 computed as a combination of onlyxt, x0, and α values; this term is implicitly returned in Equation 84 to complete the square.',\n",
       "    'We have therefore shown that at each step, xt−1 ∼q(xt−1|xt, x0) is normally distributed, with meanµq(xt, x0) that is a function of xt and x0, and variance Σq(t) as a function of α coeﬃcients.',\n",
       "    'Theseα coeﬃcients are known and ﬁxed at each timestep; they are either set permanently when modeled ashyperparameters, or treated as the current inference output of a network that seeks to model them.',\n",
       "    'FollowingEquation 84, we can rewrite our variance equation as Σq(t) = σ2q(t)I, where:σ2q(t) = (1 −αt)(1 −¯αt−1)1 −¯αt(85)In order to match approximate denoising transition step pθ(xt−1|xt) to ground-truth denoising transitionstep q(xt−1|xt, x0) as closely as possible, we can also model it as a Gaussian.',\n",
       "    'Furthermore, as all α termsare known to be frozen at each timestep, we can immediately construct the variance of the approximatedenoising transition step to also be Σq(t) = σ2q(t)I. We must parameterize its mean µθ(xt, t) as a functionof xt, however, since pθ(xt−1|xt) does not condition on x0.12']],\n",
       "  'num_chunks': 1}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "random.sample(pages_and_texts,k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def contains_math(text: str) -> bool:\n",
    "    math_patterns = [\n",
    "        # LaTeX / functional math\n",
    "        r\"\\\\[a-zA-Z]+\",                 # \\frac, \\log, \\int, etc.\n",
    "        r\"\\b(log|exp|sqrt|sigmoid|mean|var)\\b\",\n",
    "        r\"q[_\\w\\d]*\\([^)]+\\)\",          # q(z|x), q_phi(z|x)\n",
    "        r\"p[_\\w\\d]*\\([^)]+\\)\",          # p(x|z), p_theta(x|z)\n",
    "        r\"\\[[^\\]]+\\]\",                 # [log p(x)], etc.\n",
    "        r\"\\{[^}]+\\}\",                  # {...} LaTeX blocks\n",
    "\n",
    "        # Greek letters (names or Unicode)\n",
    "        r\"\\b(alpha|beta|gamma|theta|phi|mu|sigma|lambda|eta)\\b\",\n",
    "        r\"[α-ωΑ-Ω]\",                   # Unicode Greek letters\n",
    "\n",
    "        # Variables with subscripts/superscripts\n",
    "        r\"\\b[a-zA-Z]+\\d*\\_\\{?[a-zA-Z0-9]+\\}?\",   # x_t, z_{l}, etc.\n",
    "        r\"\\^{\\(?[a-zA-Z0-9]+\\)?}\",     # superscripts like x^{l}\n",
    "\n",
    "        # Unicode math symbols\n",
    "        r\"[∑∏∂∇∥≈→⇒⇔≠≤≥∞√±×÷∈∉∩∪∅⊂⊆⊄⊇⊃]\",\n",
    "        r\"\\bDKL\\b|\\bKL\\b\",            # KL divergence\n",
    "\n",
    "        # Math operators\n",
    "        r\"[*/+=<>^]\",                 # symbols often in equations\n",
    "        r\"\\bSNR\\b\",                   # signal-to-noise ratio\n",
    "        r\"\\d+\\s*[*/+=<>-]\\s*\\d+\",     # basic math ops (like 3 * 4)\n",
    "\n",
    "        # Equations or inline formulas\n",
    "        r\"[a-zA-Z0-9]+\\s*=\\s*[^\\.]+\", # equations like x = something\n",
    "    ]\n",
    "    \n",
    "    return any(re.search(pattern, text) for pattern in math_patterns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def clean_malformed_unicode(text: str) -> str:\n",
    "    \"\"\"Remove weird Unicode characters from extracted math\"\"\"\n",
    "    text = re.sub(r\"[\\u200b-\\u200f\\u202a-\\u202e\\u2060-\\u206f\\uf8e0-\\uf8ff]\", \"\", text)\n",
    "    return text\n",
    "\n",
    "def format_math_tokens(text: str) -> str:\n",
    "    \"\"\"Fix variable formatting like x1 → x_1, x1:T → x_{1:T}\"\"\"\n",
    "    text = re.sub(r\"([a-zA-Z])([0-9])\", r\"\\1_\\2\", text)  # xt → x_1\n",
    "    text = re.sub(r\"([a-zA-Z])_([a-zA-Z])\", r\"\\1_{\\2}\", text)  # x_t → x_{t}\n",
    "    text = re.sub(r\"([a-zA-Z])([0-9]+):([A-Z0-9]+)\", r\"\\1_{\\2:\\3}\", text)  # x1:T → x_{1:T}\n",
    "    return text\n",
    "\n",
    "def normalize_math_keywords(text: str) -> str:\n",
    "    \"\"\"Standardize math-related terms\"\"\"\n",
    "    text = text.replace(\"ELBO\", \"Evidence Lower Bound (ELBO)\")\n",
    "    text = re.sub(r\"\\bDKL\\b\", \"KL Divergence\", text)\n",
    "    return text\n",
    "\n",
    "def clean_math_chunk(text: str) -> str:\n",
    "    \"\"\"Apply all cleaning steps to one chunk\"\"\"\n",
    "    text = clean_malformed_unicode(text)\n",
    "    text = format_math_tokens(text)\n",
    "    text = normalize_math_keywords(text)\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:00<00:00, 1113.95it/s]\n"
     ]
    }
   ],
   "source": [
    "pages_and_chunks = []\n",
    "\n",
    "for item in tqdm(pages_and_texts):\n",
    "    for sentence_chunk in item[\"sentence_chunks\"]:\n",
    "        chunk_dict = {}\n",
    "        chunk_dict[\"page_number\"] = item[\"page_number\"]\n",
    "\n",
    "        # Join the sentences into a single string\n",
    "        joined_sentence_chunk = \"\".join(sentence_chunk).replace(\"  \", \" \").strip()\n",
    "        joined_sentence_chunk = re.sub(r'\\.([A-Z])', r'. \\1', joined_sentence_chunk)\n",
    "        joined_sentence_chunk = clean_math_chunk(joined_sentence_chunk)  \n",
    "\n",
    "\n",
    "        # Add core fields\n",
    "        chunk_dict[\"sentence_chunk\"] = joined_sentence_chunk\n",
    "        chunk_dict[\"chunk_char_count\"] = len(joined_sentence_chunk)\n",
    "        chunk_dict[\"chunk_word_count\"] = len(joined_sentence_chunk.split(\" \"))\n",
    "        chunk_dict[\"chunk_token_count\"] = len(joined_sentence_chunk) / 4  # token estimate\n",
    "\n",
    "        # Add math-aware flag\n",
    "        chunk_dict[\"contains_math\"] = contains_math(joined_sentence_chunk)\n",
    "\n",
    "        pages_and_chunks.append(chunk_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pages_and_chunks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'page_number': 21,\n",
       "  'sentence_chunk': 'We have shown that when we generalize to inﬁnite latent hierarchies, even if the encoder is trivialand the latent dimension is ﬁxed and Markovian transitions are assumed, we are still able to learn powerfulmodels of data. This suggests that further performance gains can be achieved in the case of general, deepHVAEs, where complex encoders and semantically meaningful latent spaces can be potentially learned. Acknowledgments:I would like to acknowledge Josh Dillon, Yang Song, Durk Kingma, Ben Poole,Jonathan Ho, Yiding Jiang, Ting Chen, Jeremy Cohen, and Chen Sun for reviewing drafts of this workand providing many helpful edits and comments. Thanks so much!22',\n",
       "  'chunk_char_count': 664,\n",
       "  'chunk_word_count': 101,\n",
       "  'chunk_token_count': 166.0,\n",
       "  'contains_math': False}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(pages_and_chunks,k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>chunk_char_count</th>\n",
       "      <th>chunk_word_count</th>\n",
       "      <th>chunk_token_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>41.00</td>\n",
       "      <td>41.00</td>\n",
       "      <td>41.00</td>\n",
       "      <td>41.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>12.05</td>\n",
       "      <td>1672.56</td>\n",
       "      <td>244.37</td>\n",
       "      <td>418.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.72</td>\n",
       "      <td>800.43</td>\n",
       "      <td>115.90</td>\n",
       "      <td>200.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00</td>\n",
       "      <td>192.00</td>\n",
       "      <td>26.00</td>\n",
       "      <td>48.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.00</td>\n",
       "      <td>997.00</td>\n",
       "      <td>119.00</td>\n",
       "      <td>249.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>13.00</td>\n",
       "      <td>1781.00</td>\n",
       "      <td>275.00</td>\n",
       "      <td>445.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>19.00</td>\n",
       "      <td>2304.00</td>\n",
       "      <td>331.00</td>\n",
       "      <td>576.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>22.00</td>\n",
       "      <td>3246.00</td>\n",
       "      <td>465.00</td>\n",
       "      <td>811.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       page_number  chunk_char_count  chunk_word_count  chunk_token_count\n",
       "count        41.00             41.00             41.00              41.00\n",
       "mean         12.05           1672.56            244.37             418.14\n",
       "std           7.72            800.43            115.90             200.11\n",
       "min           0.00            192.00             26.00              48.00\n",
       "25%           5.00            997.00            119.00             249.25\n",
       "50%          13.00           1781.00            275.00             445.25\n",
       "75%          19.00           2304.00            331.00             576.00\n",
       "max          22.00           3246.00            465.00             811.50"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(pages_and_chunks)\n",
    "df.describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk token count: 124.0 | Text: By combining ourparameterization of SNR in Equation 111 with our deﬁnition of SNR in Equation 109, we can also explicitlyderive elegant forms for the value of ¯αt as well as for the value of 1 −¯αt:¯αt_1 −¯αt= exp(−ωη(t))(112)∴¯αt = sigmoid(−ωη(t))(113)∴1 −¯αt = sigmoid(ωη(t))(114)These terms are necessary for a variety of computations; for example, during optimization, they are used tocreate arbitrarily noisy xt from input x_0 using the reparameterization trick, as derived in Equation 69.14\n",
      "Chunk token count: 135.25 | Text: Sliced score matching: A scalable approach to densityand score estimation. In Uncertainty in Artiﬁcial Intelligence, pages 574–584. PMLR, 2020.[17] Pascal Vincent. A connection between score matching and denoising autoencoders. Neural computation, 23(7):1661–1674, 2011.[18] Jonathan Ho, Chitwan Saharia, William Chan, David J Fleet, Mohammad Norouzi, and Tim Salimans. Cascadeddiﬀusion models for high ﬁdelity image generation. J. Mach. Learn. Res.,23:47–1, 2022.[19] Aditya Ramesh, Prafulla Dhariwal, Alex Nichol, Casey Chu, and Mark Chen.\n",
      "Chunk token count: 118.5 | Text: We can then update thejoint distribution of a Markovian HVAE (Equation 23) to write the joint distribution for a VDM as:p(x_0:T ) = p(xT )TYt=1pθ(xt−1|xt)(32)where,p(xT ) = N(xT ; 0, I)(33)Collectively, what this set of assumptions describes is a steady noisiﬁcation of an image input over time; weprogressively corrupt an image by adding Gaussian noise until eventually it becomes completely identical topure Gaussian noise. Visually, this process is depicted in Figure 3.7\n",
      "Chunk token count: 48.0 | Text: Another similar approach is energy-basedmodeling, in which a distribution is learned as an arbitrarily ﬂexible energy function that is then normalized.1arXiv:2208.11970v_1 [cs. LG] 25 Aug 2022\n",
      "Chunk token count: 104.25 | Text: Hierarchical text-conditionalimage generation with clip latents.arXiv preprint arXiv:2204.06125, 2022.[20] Prafulla Dhariwal and Alexander Nichol. Diﬀusion models beat gans on image synthesis. Advances in NeuralInformation Processing Systems, 34:8780–8794, 2021.[21] Jonathan Ho and Tim Salimans. Classiﬁer-free diﬀusion guidance. In NeurIPS 2021 Workshop on DeepGenerative Models and Downstream Applications, 2021.23\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'df' is a pandas DataFrame created from the 'pages_and_chunks' list\n",
    "\n",
    "# Show random chunks with under 30 tokens in length\n",
    "min_token_length = 150\n",
    "\n",
    "for row in df[df[\"chunk_token_count\"] <= min_token_length].sample(5).iterrows():\n",
    "    print(f'Chunk token count: {row[1][\"chunk_token_count\"]} | Text: {row[1][\"sentence_chunk\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "from uuid import uuid4\n",
    "\n",
    "# Set API key\n",
    "openai.api_key = \"sk-\"\n",
    "\n",
    "# Load your chunks\n",
    "sentences = df[\"sentence_chunk\"].tolist()\n",
    "\n",
    "# Define model\n",
    "embedding_model = \"text-embedding-3-small\"\n",
    "\n",
    "# Embed all sentence chunks\n",
    "response = openai.embeddings.create(\n",
    "    model=embedding_model,\n",
    "    input=sentences\n",
    ")\n",
    "\n",
    "# Parse results\n",
    "embeddings = [r.embedding for r in response.data]\n",
    "ids = [str(uuid4()) for _ in range(len(sentences))]\n",
    "metadatas = df[[\"page_number\", \"contains_math\"]].to_dict(orient=\"records\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:02,  2.50s/it]\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define the text chunks\n",
    "text_chunks = df[\"sentence_chunk\"].tolist()\n",
    "\n",
    "# Split into smaller batches if needed\n",
    "def batch_list(input_list, batch_size=128):\n",
    "    for i in range(0, len(input_list), batch_size):\n",
    "        yield input_list[i:i + batch_size]\n",
    "\n",
    "# Run in batches to avoid API limits\n",
    "all_embeddings = []\n",
    "\n",
    "for batch in tqdm(batch_list(text_chunks, batch_size=64)):\n",
    "    response = openai.embeddings.create(\n",
    "        model=\"text-embedding-3-small\",\n",
    "        input=batch\n",
    "    )\n",
    "    batch_embeddings = [r.embedding for r in response.data]\n",
    "    all_embeddings.extend(batch_embeddings)\n",
    "\n",
    "# all_embeddings is your final embedding list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41 41\n"
     ]
    }
   ],
   "source": [
    "print(len(text_chunks), len(all_embeddings))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv  \n",
    "\n",
    "# Create DataFrame\n",
    "text_chunks_and_embeddings_df = pd.DataFrame(pages_and_chunks)\n",
    "\n",
    "# Attach embeddings\n",
    "text_chunks_and_embeddings_df[\"embedding\"] = all_embeddings\n",
    "\n",
    "# Save safely to CSV\n",
    "embeddings_df_save_path = \"text_chunks_and_embeddings_df.csv\"\n",
    "text_chunks_and_embeddings_df.to_csv(\n",
    "    embeddings_df_save_path,\n",
    "    index=False,\n",
    "    quoting=csv.QUOTE_ALL,  \n",
    "    quotechar='\"',\n",
    "    escapechar='\\\\'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>sentence_chunk</th>\n",
       "      <th>chunk_char_count</th>\n",
       "      <th>chunk_word_count</th>\n",
       "      <th>chunk_token_count</th>\n",
       "      <th>contains_math</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Understanding Diﬀusion Models: A Uniﬁed Perspe...</td>\n",
       "      <td>1129</td>\n",
       "      <td>369</td>\n",
       "      <td>282.25</td>\n",
       "      <td>False</td>\n",
       "      <td>[0.041610248386859894, 0.011848771944642067, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>.20Classiﬁer Guidance . . . . . . . . . . . . ...</td>\n",
       "      <td>1190</td>\n",
       "      <td>255</td>\n",
       "      <td>297.50</td>\n",
       "      <td>True</td>\n",
       "      <td>[-0.010904774069786072, -0.0019216948421671987...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Another similar approach is energy-basedmodeli...</td>\n",
       "      <td>192</td>\n",
       "      <td>26</td>\n",
       "      <td>48.00</td>\n",
       "      <td>True</td>\n",
       "      <td>[-0.0441746823489666, 0.0025687962770462036, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Score-based generative models are highly relat...</td>\n",
       "      <td>2168</td>\n",
       "      <td>313</td>\n",
       "      <td>542.00</td>\n",
       "      <td>False</td>\n",
       "      <td>[-0.012235757894814014, 0.012445785105228424, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>This is because try-ing to learn a representat...</td>\n",
       "      <td>1781</td>\n",
       "      <td>267</td>\n",
       "      <td>445.25</td>\n",
       "      <td>True</td>\n",
       "      <td>[-0.0008705609361641109, 0.01104856375604868, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   page_number                                     sentence_chunk  \\\n",
       "0            0  Understanding Diﬀusion Models: A Uniﬁed Perspe...   \n",
       "1            0  .20Classiﬁer Guidance . . . . . . . . . . . . ...   \n",
       "2            0  Another similar approach is energy-basedmodeli...   \n",
       "3            1  Score-based generative models are highly relat...   \n",
       "4            1  This is because try-ing to learn a representat...   \n",
       "\n",
       "   chunk_char_count  chunk_word_count  chunk_token_count  contains_math  \\\n",
       "0              1129               369             282.25          False   \n",
       "1              1190               255             297.50           True   \n",
       "2               192                26              48.00           True   \n",
       "3              2168               313             542.00          False   \n",
       "4              1781               267             445.25           True   \n",
       "\n",
       "                                           embedding  \n",
       "0  [0.041610248386859894, 0.011848771944642067, 0...  \n",
       "1  [-0.010904774069786072, -0.0019216948421671987...  \n",
       "2  [-0.0441746823489666, 0.0025687962770462036, -...  \n",
       "3  [-0.012235757894814014, 0.012445785105228424, ...  \n",
       "4  [-0.0008705609361641109, 0.01104856375604868, ...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import saved file and view\n",
    "text_chunks_and_embedding_df_load = pd.read_csv(embeddings_df_save_path)\n",
    "text_chunks_and_embedding_df_load.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41, 1536)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ast\n",
    "import numpy as np\n",
    "\n",
    "# Convert 'embedding' column from string to list of floats\n",
    "text_chunks_and_embedding_df_load[\"embedding\"] = text_chunks_and_embedding_df_load[\"embedding\"].apply(ast.literal_eval)\n",
    "\n",
    "# Create NumPy array of embeddings\n",
    "embedding_array = np.array(text_chunks_and_embedding_df_load[\"embedding\"].to_list()).astype(\"float32\")\n",
    "embedding_array.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Explain the ELBO objective in Variational Diffusion Models\n",
      "Time taken for similarity computation: 0.00322 seconds.\n",
      "\n",
      "Top retrieved chunks:\n",
      "\n",
      "--- Score: 0.5705 ---\n",
      "First, we derive Variational DiﬀusionModels as a special case of a Markovian Hierarchical Variational Autoencoder, where three key assumptionsenable tractable computation and scalable optimization of the Evidence Lower Bound (ELBO). We then prove that optimizing a VDMboils down to learning a neural network to predict one of three potential objectives: the original source imagefrom any arbitrary noisiﬁcation of it, the original source noise from any arbitrarily noisiﬁed image, or thescore function of a noisiﬁed image at any arbitrary noise level. Then, we dive deeper into what it means tolearn the score function, and connect it explicitly with the perspective of Score-based Generative Modeling. Lastly, we cover how to learn a conditional distribution using diﬀusion models. In summary, diﬀusion models have shown incredible capabilities as generative models; indeed, they powerthe current state-of-the-art models on text-conditioned image generation such as Imagen and DALL-E 2. Furthermore, the mathematics that enable these models are exceedingly elegant. However, there still remaina few drawbacks to consider:• It is unlikely that this is how we, as humans, naturally model and generate data; we do not generatesamples as random noise that we iteratively denoise.• The VDM does not produce interpretable latents. Whereas a VAE would hopefully learn a structuredlatent space through the optimization of its encoder, in a VDM the encoder at each timestep is alreadygiven as a linear Gaussian model and cannot be optimized ﬂexibly. Therefore, the intermediate latentsare restricted as just noisy versions of the original input.• The latents are restricted to the same dimensionality as the original input, further frustrating eﬀortsto learn meaningful, compressed latent structure.• Sampling is an expensive procedure, as multiple denoising steps must be run under both formulations. Recall that one of the restrictions is that a large enough number of timesteps T is chosen to ensure theﬁnal latent is completely Gaussian noise; during sampling we must iterate over all these timesteps togenerate a sample. As a ﬁnal note, the success of diﬀusion models highlights the power of Hierarchical VAEs as a generativemodel.\n",
      "\n",
      "--- Score: 0.5447 ---\n",
      "= Eq(x_1:T |x_0)log p(xT )pθ(x_0|x_1)q(x_1|x_0)+ logTYt=2pθ(xt−1|xt)q(xt−1|xt,x_0)\u0018\u0018\u0018\u0018q(xt|x_0)(((((q(xt−1|x_0)(53)= Eq(x_1:T |x_0)\"log p(xT )pθ(x_0|x_1)\u0018\u0018\u0018\u0018q(x_1|x_0)+ log \u0018\u0018\u0018\u0018q(x_1|x_0)q(xT |x_0) + logTYt=2pθ(xt−1|xt)q(xt−1|xt, x_0)#(54)= Eq(x_1:T |x_0)\"log p(xT )pθ(x_0|x_1)q(xT |x_0)+TXt=2logpθ(xt−1|xt)q(xt−1|xt, x_0)#(55)= Eq(x_1:T |x_0) [log pθ(x_0|x_1)] + Eq(x_1:T |x_0)\u0014logp(xT )q(xT |x_0)\u0015+TXt=2Eq(x_1:T |x_0)\u0014logpθ(xt−1|xt)q(xt−1|xt, x_0)\u0015(56)= Eq(x_1|x_0) [log pθ(x_0|x_1)] + Eq(xT |x_0)\u0014logp(xT )q(xT |x_0)\u0015+TXt=2Eq(xt,xt−1|x_0)\u0014logpθ(xt−1|xt)q(xt−1|xt, x_0)\u0015(57)= Eq(x_1|x_0) [log pθ(x_0|x_1)]|{z}reconstruction term−KL Divergence(q(xT |x_0) ∥p(xT ))|{z}prior matching term−TXt=2Eq(xt|x_0) [KL Divergence(q(xt−1|xt, x_0) ∥pθ(xt−1|xt))]|{z}denoising matching term(58)We have therefore successfully derived an interpretation for the Evidence Lower Bound (ELBO) that can be estimated with lowervariance, as each term is computed as an expectation of at most one random variable at a time. Thisformulation also has an elegant interpretation, which is revealed when inspecting each individual term:1. Eq(x_1|x_0) [log pθ(x_0|x_1)] can be interpreted as a reconstruction term; like its analogue in the Evidence Lower Bound (ELBO) ofa vanilla VAE, this term can be approximated and optimized using a Monte Carlo estimate.2. KL Divergence(q(xT |x_0) ∥p(xT )) represents how close the distribution of the ﬁnal noisiﬁed input is to the stan-dard Gaussian prior. It has no trainable parameters, and is also equal to zero under our assumptions.3. Eq(xt|x_0) [KL Divergence(q(xt−1|xt, x_0) ∥pθ(xt−1|xt))] is a denoising matching term. We learn desired denoisingtransition step pθ(xt−1|xt) as an approximation to tractable, ground-truth denoising transition stepq(xt−1|xt, x_0). The q(xt−1|xt, x_0) transition step can act as a ground-truth signal, since it deﬁneshow to denoise a noisy image xt with access to what the ﬁnal, completely denoised image x_0 shouldbe. This term is therefore minimized when the two denoising steps match as closely as possible, asmeasured by their KL Divergence. As a side note, one observes that in the process of both Evidence Lower Bound (ELBO) derivations (Equation 45 and Equation 58),only the Markov assumption is used; as a result these formulae will hold true for any arbitrary MarkovianHVAE.\n",
      "\n",
      "--- Score: 0.5301 ---\n",
      "Figure 1: A Variational Autoencoder graphically represented. Here, encoder q(z|x) deﬁnes a distributionover latent variables z for observations x, and p(x|z) decodes latent variables into observations. Secondly, we explore why we seek to maximize the Evidence Lower Bound (ELBO). Having introduced latent variables z that wewould like to model, our goal is to learn this underlying latent structure that describes our observed data. Inother words, we want to optimize the parameters of our variational posterior qφ(z|x) to exactly match thetrue posterior distribution p(z|x), which is achieved by minimizing their KL Divergence (ideally to zero). Unfortunately, it is intractable to minimize this KL Divergence term directly, as we do not have access to theground truth p(z|x) distribution. However, notice that on the left hand side of Equation 15, the likelihood ofour data (and therefore our evidence term log p(x)) is always a constant with respect to φ, as it is computedby marginalizing out all latents z from the joint distribution p(x, z) and does not depend on φ whatsoever. Since the Evidence Lower Bound (ELBO) and KL Divergence terms sum up to a constant, any maximization of the Evidence Lower Bound (ELBO) term withrespect to φ necessarily invokes an equal minimization of the KL Divergence term. Thus, the Evidence Lower Bound (ELBO) can bemaximized as a proxy for learning how to perfectly model the true latent posterior distribution; the morewe optimize the Evidence Lower Bound (ELBO), the closer our approximate posterior gets to the true posterior. Additionally, oncetrained, the Evidence Lower Bound (ELBO) can be used to estimate the likelihood of observed or generated data as well, since it islearned to approximate the model evidence log p(x). Variational AutoencodersIn the default formulation of the Variational Autoencoder (VAE) [1], we directly maximize the Evidence Lower Bound (ELBO). Thisapproach is variational, because we optimize for the best qφ(z|x) amongst a family of potential posteriordistributions parameterized by φ.\n",
      "\n",
      "--- Score: 0.5271 ---\n",
      "Note that our encoder distributions q(xt|xt−1) are no longer parameterized by φ, as they are completelymodeled as Gaussians with deﬁned mean and variance parameters at each timestep. Therefore, in a VDM, weare only interested in learning conditionals pθ(xt−1|xt), so that we can simulate new data. After optimizingthe VDM, the sampling procedure is as simple as sampling Gaussian noise from p(xT ) and iteratively runningthe denoising transitions pθ(xt−1|xt) for T steps to generate a novel x_0. Like any HVAE, the VDM can be optimized by maximizing the Evidence Lower Bound (ELBO), which can be derived as:log p(x) = logZp(x_0:T )dx_1:T(34)= logZ p(x_0:T )q(x_1:T |x_0)q(x_1:T |x_0)dx_1:T(35)= log Eq(x_1:T |x_0)\u0014p(x_0:T )q(x_1:T |x_0)\u0015(36)≥Eq(x_1:T |x_0)\u0014logp(x_0:T )q(x_1:T |x_0)\u0015(37)= Eq(x_1:T |x_0)\"log p(xT ) QTt=1 pθ(xt−1|xt)QTt=1 q(xt|xt−1)#(38)= Eq(x_1:T |x_0)\"log p(xT )pθ(x_0|x_1) QTt=2 pθ(xt−1|xt)q(xT |xT −1) QT −1t=1 q(xt|xt−1)#(39)= Eq(x_1:T |x_0)\"log p(xT )pθ(x_0|x_1) QT −1t=1 pθ(xt|xt+1)q(xT |xT −1) QT −1t=1 q(xt|xt−1)#(40)= Eq(x_1:T |x_0)\u0014log p(xT )pθ(x_0|x_1)q(xT |xT −1)\u0015+ Eq(x_1:T |x_0)\"logT −1Yt=1pθ(xt|xt+1)q(xt|xt−1)#(41)= Eq(x_1:T |x_0) [log pθ(x_0|x_1)] + Eq(x_1:T |x_0)\u0014logp(xT )q(xT |xT −1)\u0015+ Eq(x_1:T |x_0)\"T −1Xt=1log pθ(xt|xt+1)q(xt|xt−1)#(42)= Eq(x_1:T |x_0) [log pθ(x_0|x_1)] + Eq(x_1:T |x_0)\u0014logp(xT )q(xT |xT −1)\u0015+T −1Xt=1Eq(x_1:T |x_0)\u0014log pθ(xt|xt+1)q(xt|xt−1)\u0015(43)= Eq(x_1|x_0) [log pθ(x_0|x_1)] + Eq(xT −1,xT |x_0)\u0014logp(xT )q(xT |xT −1)\u0015+T −1Xt=1Eq(xt−1,xt,xt+1|x_0)\u0014log pθ(xt|xt+1)q(xt|xt−1)\u0015(44)= Eq(x_1|x_0) [log pθ(x_0|x_1)]|{z}reconstruction term−Eq(xT −1|x_0) [KL Divergence(q(xT |xT −1) ∥p(xT ))]|{z}prior matching term−T −1Xt=1Eq(xt−1,xt+1|x_0) [KL Divergence(q(xt|xt−1) ∥pθ(xt|xt+1))]|{z}consistency term(45)The derived form of the Evidence Lower Bound (ELBO) can be interpreted in terms of its individual components:1. Eq(x_1|x_0) [log pθ(x_0|x_1)] can be interpreted as a reconstruction term, predicting the log probability ofthe original data sample given the ﬁrst-step latent. This term also appears in a vanilla VAE, and canbe trained similarly.2. Eq(xT −1|x_0) [KL Divergence(q(xT |xT −1) ∥p(xT ))] is a prior matching term; it is minimized when the ﬁnal latentdistribution matches the Gaussian prior. This term requires no optimization, as it has no trainableparameters; furthermore, as we have assumed a large enough T such that the ﬁnal distribution isGaussian, this term eﬀectively becomes zero.3. Eq(xt−1,xt+1|x_0) [KL Divergence(q(xt|xt−1) ∥pθ(xt|xt+1))] is a consistency term; it endeavors to make the distri-bution at xt consistent, from both forward and backward processes. That is, a denoising step from anoisier image should match the corresponding noising step from a cleaner image, for every intermediatetimestep; this is reﬂected mathematically by the KL Divergence. This term is minimized when we trainpθ(xt|xt+1) to match the Gaussian distribution q(xt|xt−1), which is deﬁned in Equation 31.8\n",
      "\n",
      "--- Score: 0.5264 ---\n",
      "It is called an autoencoder because it is reminiscent of a traditional au-toencoder model, where input data is trained to predict itself after undergoing an intermediate bottleneckingrepresentation step. To make this connection explicit, let us dissect the Evidence Lower Bound (ELBO) term further:Eqφ(z|x)\u0014log p(x, z)qφ(z|x)\u0015= Eqφ(z|x)\u0014log pθ(x|z)p(z)qφ(z|x)\u0015(Chain Rule of Probability)(17)= Eqφ(z|x) [log pθ(x|z)] + Eqφ(z|x)\u0014logp(z)qφ(z|x)\u0015(Split the Expectation)(18)= Eqφ(z|x) [log pθ(x|z)]|{z}reconstruction term−KL Divergence(qφ(z|x) ∥p(z))|{z}prior matching term(Deﬁnition of KL Divergence) (19)In this case, we learn an intermediate bottlenecking distribution qφ(z|x) that can be treated as an encoder; ittransforms inputs into a distribution over possible latents. Simultaneously, we learn a deterministic functionpθ(x|z) to convert a given latent vector z into an observation x, which can be interpreted as a decoder. The two terms in Equation 19 each have intuitive descriptions: the ﬁrst term measures the reconstructionlikelihood of the decoder from our variational distribution; this ensures that the learned distribution ismodeling eﬀective latents that the original data can be regenerated from. The second term measures howsimilar the learned variational distribution is to a prior belief held over latent variables. Minimizing thisterm encourages the encoder to actually learn a distribution rather than collapse into a Dirac delta function. Maximizing the Evidence Lower Bound (ELBO) is thus equivalent to maximizing its ﬁrst term and minimizing its second term.4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import openai\n",
    "from time import perf_counter as timer\n",
    "\n",
    "# ---- 1. Load data ----\n",
    "import pandas as pd\n",
    "text_chunks_and_embedding_df_load = pd.read_csv(\"text_chunks_and_embeddings_df.csv\")\n",
    "\n",
    "# Convert stringified embeddings back to list of floats\n",
    "import ast\n",
    "text_chunks_and_embedding_df_load[\"embedding\"] = text_chunks_and_embedding_df_load[\"embedding\"].apply(ast.literal_eval)\n",
    "embedding_array = np.array(text_chunks_and_embedding_df_load[\"embedding\"].tolist()).astype(\"float32\")\n",
    "\n",
    "# ---- 2. Define and embed your query ----\n",
    "query = \"Explain the ELBO objective in Variational Diffusion Models\"\n",
    "\n",
    "print(f\"Query: {query}\")\n",
    "\n",
    "response = openai.embeddings.create(\n",
    "    model=\"text-embedding-3-small\",  # must match document embedding model\n",
    "    input=[query]\n",
    ")\n",
    "query_embedding = np.array(response.data[0].embedding).astype(\"float32\")\n",
    "\n",
    "# ---- 3. Normalize embeddings for cosine similarity ----\n",
    "def normalize(vectors):\n",
    "    norms = np.linalg.norm(vectors, axis=1, keepdims=True)\n",
    "    return vectors / norms\n",
    "\n",
    "embedding_array_normalized = normalize(embedding_array)\n",
    "query_embedding_normalized = normalize(query_embedding.reshape(1, -1))\n",
    "\n",
    "# ---- 4. Compute cosine similarity ----\n",
    "start_time = timer()\n",
    "cosine_scores = np.dot(embedding_array_normalized, query_embedding_normalized.T).flatten()\n",
    "end_time = timer()\n",
    "print(f\"Time taken for similarity computation: {end_time - start_time:.5f} seconds.\")\n",
    "\n",
    "# ---- 5. Retrieve top-k most similar chunks ----\n",
    "top_k = 5\n",
    "top_indices = np.argsort(cosine_scores)[-top_k:][::-1]\n",
    "\n",
    "print(\"\\nTop retrieved chunks:\\n\")\n",
    "for idx in top_indices:\n",
    "    score = cosine_scores[idx]\n",
    "    chunk = text_chunks_and_embedding_df_load.iloc[idx][\"sentence_chunk\"]\n",
    "    print(f\"--- Score: {score:.4f} ---\\n{chunk}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Successfully stored 41 chunks in ChromaDB.\n"
     ]
    }
   ],
   "source": [
    "#!pip install chromadb --quiet\n",
    "\n",
    "import chromadb\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load your saved DataFrame\n",
    "df = pd.read_csv(\"text_chunks_and_embeddings_df.csv\", converters={\"embedding\": eval})\n",
    "\n",
    "# Initialize persistent ChromaDB client\n",
    "client = chromadb.Client(chromadb.config.Settings(\n",
    "    persist_directory=\"./saral_chroma_store\"  # directory where Chroma saves\n",
    "))\n",
    "\n",
    "# Create or get a collection\n",
    "collection = client.get_or_create_collection(\n",
    "    name=\"saral_diffusion_chunks\",\n",
    "    metadata={\"source\": \"Diffusion Models PDF\"}\n",
    ")\n",
    "\n",
    "# Prepare data for ingestion\n",
    "texts = df[\"sentence_chunk\"].tolist()\n",
    "metadatas = df[[\"page_number\", \"contains_math\"]].to_dict(orient=\"records\")\n",
    "ids = [f\"chunk_{i}\" for i in range(len(df))]\n",
    "embeddings = np.array(df[\"embedding\"].tolist())\n",
    "\n",
    "# Add all embeddings to the collection\n",
    "collection.add(\n",
    "    ids=ids,\n",
    "    documents=texts,\n",
    "    embeddings=embeddings,\n",
    "    metadatas=metadatas\n",
    ")\n",
    "\n",
    "print(f\"✅ Successfully stored {len(texts)} chunks in ChromaDB.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 Result 1 — Page 21, Math: False\n",
      "First, we derive Variational DiﬀusionModels as a special case of a Markovian Hierarchical Variational Autoencoder, where three key assumptionsenable tractable computation and scalable optimization of the Evidence Lower Bound (ELBO). We then prove that optimizing a VDMboils down to learning a neural network to predict one of three potential objectives: the original source imagefrom any arbitrary no ...\n",
      "\n",
      "🔹 Result 2 — Page 9, Math: True\n",
      "= Eq(x_1:T |x_0)log p(xT )pθ(x_0|x_1)q(x_1|x_0)+ logTYt=2pθ(xt−1|xt)q(xt−1|xt,x_0)\u0018\u0018\u0018\u0018q(xt|x_0)(((((q(xt−1|x_0)(53)= Eq(x_1:T |x_0)\"log p(xT )pθ(x_0|x_1)\u0018\u0018\u0018\u0018q(x_1|x_0)+ log \u0018\u0018\u0018\u0018q(x_1|x_0)q(xT |x_0) + logTYt=2pθ(xt−1|xt)q(xt−1|xt, x_0)#(54)= Eq(x_1:T |x_0)\"log p(xT )pθ(x_0|x_1)q(xT |x_0)+TXt=2logpθ(xt−1|xt)q(xt−1|xt, x_0)#(55)= Eq(x_1:T |x_0) [log pθ(x_0|x_1)] + Eq(x_1:T |x_0)\u0014logp(xT )q(xT |x_0)\u0015+ ...\n",
      "\n",
      "🔹 Result 3 — Page 3, Math: True\n",
      "Figure 1: A Variational Autoencoder graphically represented. Here, encoder q(z|x) deﬁnes a distributionover latent variables z for observations x, and p(x|z) decodes latent variables into observations. Secondly, we explore why we seek to maximize the Evidence Lower Bound (ELBO). Having introduced latent variables z that wewould like to model, our goal is to learn this underlying latent structure t ...\n",
      "\n",
      "🔹 Result 4 — Page 7, Math: True\n",
      "Note that our encoder distributions q(xt|xt−1) are no longer parameterized by φ, as they are completelymodeled as Gaussians with deﬁned mean and variance parameters at each timestep. Therefore, in a VDM, weare only interested in learning conditionals pθ(xt−1|xt), so that we can simulate new data. After optimizingthe VDM, the sampling procedure is as simple as sampling Gaussian noise from p(xT ) an ...\n",
      "\n",
      "🔹 Result 5 — Page 3, Math: True\n",
      "It is called an autoencoder because it is reminiscent of a traditional au-toencoder model, where input data is trained to predict itself after undergoing an intermediate bottleneckingrepresentation step. To make this connection explicit, let us dissect the Evidence Lower Bound (ELBO) term further:Eqφ(z|x)\u0014log p(x, z)qφ(z|x)\u0015= Eqφ(z|x)\u0014log pθ(x|z)p(z)qφ(z|x)\u0015(Chain Rule of Probability)(17)= Eqφ(z|x ...\n"
     ]
    }
   ],
   "source": [
    "query = \"Explain the ELBO objective in Variational Diffusion Models\"\n",
    "\n",
    "# Embed the query (must match your embedding model)\n",
    "query_emb = openai.embeddings.create(\n",
    "    model=\"text-embedding-3-small\",\n",
    "    input=[query]\n",
    ").data[0].embedding\n",
    "\n",
    "# Retrieve top-5 relevant chunks\n",
    "results = collection.query(\n",
    "    query_embeddings=[query_emb],\n",
    "    n_results=5\n",
    ")\n",
    "\n",
    "# Display results\n",
    "for i, (doc, meta) in enumerate(zip(results[\"documents\"][0], results[\"metadatas\"][0])):\n",
    "    print(f\"\\n🔹 Result {i+1} — Page {meta['page_number']}, Math: {meta['contains_math']}\")\n",
    "    print(doc[:400], \"...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_relevant_chunks(query: str, top_k: int = 5):\n",
    "    \"\"\"\n",
    "    Retrieves top-k chunks relevant to the query.\n",
    "    Automatically prioritizes math-heavy chunks if query looks mathematical.\n",
    "    \"\"\"\n",
    "    import re\n",
    "\n",
    "    # Detect if query is math-related\n",
    "    math_query_terms = [\"derive\", \"derivation\", \"prove\", \"formula\", \"equation\", \"show that\"]\n",
    "    is_math_query = any(re.search(rf\"\\b{t}\\b\", query.lower()) for t in math_query_terms)\n",
    "\n",
    "    # Generate query embedding\n",
    "    query_emb = openai.embeddings.create(\n",
    "        model=\"text-embedding-3-small\",\n",
    "        input=[query]\n",
    "    ).data[0].embedding\n",
    "\n",
    "    # Apply math filter dynamically (only if needed)\n",
    "    where_clause = {\"contains_math\": True} if is_math_query else None\n",
    "\n",
    "    results = collection.query(\n",
    "        query_embeddings=[query_emb],\n",
    "        n_results=top_k,\n",
    "        where=where_clause\n",
    "    )\n",
    "\n",
    "    chunks = []\n",
    "    for doc, meta in zip(results[\"documents\"][0], results[\"metadatas\"][0]):\n",
    "        chunks.append({\n",
    "            \"text\": doc,\n",
    "            \"page_number\": meta.get(\"page_number\", \"?\"),\n",
    "            \"contains_math\": meta.get(\"contains_math\", False)\n",
    "        })\n",
    "    return chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 Result 1: (Page 21, Math: False)\n",
      "First, we derive Variational DiﬀusionModels as a special case of a Markovian Hierarchical Variational Autoencoder, where three key assumptionsenable tractable computation and scalable optimization of the Evidence Lower Bound (ELBO). We then prove that optimizing a VDMboils down to learning a neural network to predict one of three potential objectives: the original source imagefrom any arbitrary noisiﬁcation of it, the original source noise from any arbitrarily noisiﬁed image, or thescore functio ...\n",
      "\n",
      "🔹 Result 2: (Page 9, Math: True)\n",
      "= Eq(x_1:T |x_0)log p(xT )pθ(x_0|x_1)q(x_1|x_0)+ logTYt=2pθ(xt−1|xt)q(xt−1|xt,x_0)\u0018\u0018\u0018\u0018q(xt|x_0)(((((q(xt−1|x_0)(53)= Eq(x_1:T |x_0)\"log p(xT )pθ(x_0|x_1)\u0018\u0018\u0018\u0018q(x_1|x_0)+ log \u0018\u0018\u0018\u0018q(x_1|x_0)q(xT |x_0) + logTYt=2pθ(xt−1|xt)q(xt−1|xt, x_0)#(54)= Eq(x_1:T |x_0)\"log p(xT )pθ(x_0|x_1)q(xT |x_0)+TXt=2logpθ(xt−1|xt)q(xt−1|xt, x_0)#(55)= Eq(x_1:T |x_0) [log pθ(x_0|x_1)] + Eq(x_1:T |x_0)\u0014logp(xT )q(xT |x_0)\u0015+TXt=2Eq(x_1:T |x_0)\u0014logpθ(xt−1|xt)q(xt−1|xt, x_0)\u0015(56)= Eq(x_1|x_0) [log pθ(x_0|x_1)] + Eq(xT |x_0)\u0014 ...\n",
      "\n",
      "🔹 Result 3: (Page 3, Math: True)\n",
      "Figure 1: A Variational Autoencoder graphically represented. Here, encoder q(z|x) deﬁnes a distributionover latent variables z for observations x, and p(x|z) decodes latent variables into observations. Secondly, we explore why we seek to maximize the Evidence Lower Bound (ELBO). Having introduced latent variables z that wewould like to model, our goal is to learn this underlying latent structure that describes our observed data. Inother words, we want to optimize the parameters of our variationa ...\n",
      "\n",
      "🔹 Result 4: (Page 7, Math: True)\n",
      "Note that our encoder distributions q(xt|xt−1) are no longer parameterized by φ, as they are completelymodeled as Gaussians with deﬁned mean and variance parameters at each timestep. Therefore, in a VDM, weare only interested in learning conditionals pθ(xt−1|xt), so that we can simulate new data. After optimizingthe VDM, the sampling procedure is as simple as sampling Gaussian noise from p(xT ) and iteratively runningthe denoising transitions pθ(xt−1|xt) for T steps to generate a novel x_0. Like ...\n",
      "\n",
      "🔹 Result 5: (Page 3, Math: True)\n",
      "It is called an autoencoder because it is reminiscent of a traditional au-toencoder model, where input data is trained to predict itself after undergoing an intermediate bottleneckingrepresentation step. To make this connection explicit, let us dissect the Evidence Lower Bound (ELBO) term further:Eqφ(z|x)\u0014log p(x, z)qφ(z|x)\u0015= Eqφ(z|x)\u0014log pθ(x|z)p(z)qφ(z|x)\u0015(Chain Rule of Probability)(17)= Eqφ(z|x) [log pθ(x|z)] + Eqφ(z|x)\u0014logp(z)qφ(z|x)\u0015(Split the Expectation)(18)= Eqφ(z|x) [log pθ(x|z)]|{z}rec ...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# (Optional) still load df if you need metadata for inspection later\n",
    "df = pd.read_csv(\"text_chunks_and_embeddings_df.csv\", converters={\"embedding\": eval})\n",
    "\n",
    "query = \"Explain the ELBO objective in Variational Diffusion Models\"\n",
    "\n",
    "results = retrieve_relevant_chunks(query=query, top_k=5)\n",
    "\n",
    "# Display the retrieved chunks\n",
    "for i, res in enumerate(results, start=1):\n",
    "    print(f\"\\n🔹 Result {i}: (Page {res['page_number']}, Math: {res['contains_math']})\")\n",
    "    print(res['text'][:500], \"...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Page 21 | Math: False | Distance: 0.8590\n",
      "First, we derive Variational DiﬀusionModels as a special case of a Markovian Hierarchical Variational Autoencoder, where three key assumptionsenable tractable computation and scalable optimization of the Evidence Lower Bound (ELBO). We then prove that optimizing a VDMboils down to learning a neural network to predict one of three potential objectives: the original source imagefrom any arbitrary no ...\n",
      "\n",
      " Page 9 | Math: True | Distance: 0.9107\n",
      "= Eq(x_1:T |x_0)log p(xT )pθ(x_0|x_1)q(x_1|x_0)+ logTYt=2pθ(xt−1|xt)q(xt−1|xt,x_0)\u0018\u0018\u0018\u0018q(xt|x_0)(((((q(xt−1|x_0)(53)= Eq(x_1:T |x_0)\"log p(xT )pθ(x_0|x_1)\u0018\u0018\u0018\u0018q(x_1|x_0)+ log \u0018\u0018\u0018\u0018q(x_1|x_0)q(xT |x_0) + logTYt=2pθ(xt−1|xt)q(xt−1|xt, x_0)#(54)= Eq(x_1:T |x_0)\"log p(xT )pθ(x_0|x_1)q(xT |x_0)+TXt=2logpθ(xt−1|xt)q(xt−1|xt, x_0)#(55)= Eq(x_1:T |x_0) [log pθ(x_0|x_1)] + Eq(x_1:T |x_0)\u0014logp(xT )q(xT |x_0)\u0015+ ...\n",
      "\n",
      " Page 3 | Math: True | Distance: 0.9398\n",
      "Figure 1: A Variational Autoencoder graphically represented. Here, encoder q(z|x) deﬁnes a distributionover latent variables z for observations x, and p(x|z) decodes latent variables into observations. Secondly, we explore why we seek to maximize the Evidence Lower Bound (ELBO). Having introduced latent variables z that wewould like to model, our goal is to learn this underlying latent structure t ...\n",
      "\n",
      " Page 7 | Math: True | Distance: 0.9457\n",
      "Note that our encoder distributions q(xt|xt−1) are no longer parameterized by φ, as they are completelymodeled as Gaussians with deﬁned mean and variance parameters at each timestep. Therefore, in a VDM, weare only interested in learning conditionals pθ(xt−1|xt), so that we can simulate new data. After optimizingthe VDM, the sampling procedure is as simple as sampling Gaussian noise from p(xT ) an ...\n",
      "\n",
      " Page 3 | Math: True | Distance: 0.9473\n",
      "It is called an autoencoder because it is reminiscent of a traditional au-toencoder model, where input data is trained to predict itself after undergoing an intermediate bottleneckingrepresentation step. To make this connection explicit, let us dissect the Evidence Lower Bound (ELBO) term further:Eqφ(z|x)\u0014log p(x, z)qφ(z|x)\u0015= Eqφ(z|x)\u0014log pθ(x|z)p(z)qφ(z|x)\u0015(Chain Rule of Probability)(17)= Eqφ(z|x ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = collection.query(\n",
    "    query_embeddings=[query_emb],\n",
    "    n_results=top_k,\n",
    "    include=[\"documents\", \"metadatas\", \"distances\"]\n",
    ")\n",
    "for doc, meta, dist in zip(results[\"documents\"][0], results[\"metadatas\"][0], results[\"distances\"][0]):\n",
    "    print(f\" Page {meta['page_number']} | Math: {meta['contains_math']} | Distance: {dist:.4f}\")\n",
    "    print(doc[:400], \"...\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using attention implementation: sdpa\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from transformers import BitsAndBytesConfig\n",
    "from transformers.utils import is_flash_attn_2_available\n",
    "use_quantization_config = True  # Use 4-bit quantization if needed (you can change it)\n",
    "# Quantization config\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16\n",
    ")\n",
    "\n",
    "# Flash Attention setup (optional, performance boost)\n",
    "if is_flash_attn_2_available() and torch.cuda.get_device_capability(0)[0] >= 8:\n",
    "    attn_implementation = \"flash_attention_2\"\n",
    "else:\n",
    "    attn_implementation = \"sdpa\"\n",
    "\n",
    "print(f\"[INFO] Using attention implementation: {attn_implementation}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using model_id: google/gemma-7b-it\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:18<00:00,  4.73s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model_id = \"google/gemma-7b-it\"\n",
    "print(f\"[INFO] Using model_id: {model_id}\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "llm_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.float16,\n",
    "    quantization_config=quantization_config if use_quantization_config else None,\n",
    "    low_cpu_mem_usage=True,\n",
    "    attn_implementation=attn_implementation,\n",
    ")\n",
    "\n",
    "if not use_quantization_config:\n",
    "    llm_model.to(\"cuda\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SARAL-style GPT-generated queries\n",
    "gpt4_queries = [\n",
    "    \"Make a 7-slide talk for graduate students focusing on methods; include 3 speaker notes per slide and preserve key equations.\",\n",
    "    \"Create a 90-second script in plain English summarizing the key contributions of this paper.\",\n",
    "    \"Write a press release explaining the core findings of this paper to a general audience.\",\n",
    "    \"Generate a 5-minute technical script to accompany a slide presentation on the paper's mathematical formulation.\",\n",
    "    \"Make a tweet thread (10 tweets) summarizing the main points of the paper with inline LaTeX for equations.\",\n",
    "    \"Create 5 bullet points per slide for a 10-slide deck aimed at machine learning practitioners.\",\n",
    "    \"Summarize the paper’s introduction and related work in a style suitable for policymakers unfamiliar with AI.\",\n",
    "    \"Generate speaker notes that include exact mathematical notation for each equation-heavy section.\",\n",
    "    \"Create a 30-second elevator pitch version of this paper for a research pitch competition.\",\n",
    "    \"Write a detailed walkthrough of the model section of the paper with inline LaTeX and citation to source chunks.\"\n",
    "]\n",
    "# Manually created SARAL iteration-style queries\n",
    "manual_queries = [\n",
    "    \"Make slide 3 more visual and reduce jargon.\",\n",
    "    \"Simplify the explanation of ELBO for a non-technical audience.\",\n",
    "    \"Turn slide 5’s script into a short 3-bullet executive summary.\",\n",
    "    \"Add analogies to slide 2 that help explain diffusion models.\",\n",
    "    \"Reformat speaker notes to include numbered references to the paper’s equations.\",\n",
    "    \"Shorten the full script to fit in a 90-second narration window.\",\n",
    "    \"Turn the bullet points from slide 4 into LinkedIn post format.\",\n",
    "    \"Generate a layman’s explanation of the model with no equations.\",\n",
    "    \"Add 3 citations to slide 1's script using page numbers from the paper.\",\n",
    "    \"Explain the limitations of the method section in a debate-style tone.\"\n",
    "\n",
    "]\n",
    "formula_queries = [\n",
    "    \"Give the final ELBO formula used in this paper, with LaTeX formatting and page reference.\",\n",
    "    \"Summarize the key equation for the KL Divergence in this paper, with brief explanation.\",\n",
    "    \"List all major mathematical equations used in the model section with page numbers.\",\n",
    "    \"Extract the loss function from the method section with proper LaTeX formatting.\",\n",
    "    \"Present the final form of the diffusion process equation as described in the paper.\",\n",
    "    \"Derive the ELBO objective step-by-step as shown in the paper.\",\n",
    "    \"Show a complete derivation of the KL divergence term used in optimization.\",\n",
    "    \"Explain and derive how the reparameterization trick is applied in this model.\",\n",
    "    \"Walk through the derivation of the variational lower bound from first principles.\",\n",
    "    \"Derive the final expression used to estimate the transition probability in VDMs.\",\n",
    "    \"Derive the ELBO objective function step-by-step.\",\n",
    "    \"Prove the KL divergence term in the VAE loss.\",\n",
    "    \"Show that ELBO is a lower bound on the log evidence.\",\n",
    "    \"Start from Bayes rule and derive the ELBO formula for a VAE.\",\n",
    "    \"Show full derivation of ELBO in HVAE models.\"\n",
    "\n",
    "]\n",
    "\n",
    "query_list = gpt4_queries + manual_queries + formula_queries\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Query:\n",
      "Shorten the full script to fit in a 90-second narration window.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "query = random.choice(query_list)\n",
    "print(f\"Selected Query:\\n{query}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_formatter(query: str, context_items: list[dict], audience: str = \"general\") -> str:\n",
    "    \"\"\"\n",
    "    Builds an adaptive, paper-agnostic prompt.\n",
    "    Supports derivation, script, and explanation modes.\n",
    "    \"\"\"\n",
    "\n",
    "    # --- Handle empty context ---\n",
    "    if not context_items:\n",
    "        context_items = [{\"page_number\": \"?\", \"sentence_chunk\": \"No relevant context retrieved.\"}]\n",
    "\n",
    "    context = \"\\n\\n\".join(\n",
    "        f\"[Page {item.get('page_number', '?')}] {item['sentence_chunk']}\"\n",
    "        for item in context_items\n",
    "    )\n",
    "\n",
    "    # --- Detect query intent ---\n",
    "    derivation_terms = [\"derive\", \"proof\", \"prove\", \"show that\", \"formula\", \"equation\"]\n",
    "    script_terms = [\"script\", \"presentation\", \"talk\", \"slides\", \"narration\"]\n",
    "    is_derivation = any(term in query.lower() for term in derivation_terms)\n",
    "    is_script = any(term in query.lower() for term in script_terms)\n",
    "\n",
    "    # --- Base intro (prompt header) ---\n",
    "    base_prompt = \"\"\"\n",
    "You are SARAL, a research communication assistant that generates adaptive slide decks,\n",
    "scripts, and summaries from academic papers for {audience} audiences.\n",
    "\n",
    "You will use only the context provided below to answer the query.\n",
    "If the paper does NOT contain enough information to answer, explicitly say:\n",
    "\"Not enough information in the paper to derive or explain this.\"\n",
    "\n",
    "---\n",
    "\n",
    "### Context (from paper):\n",
    "{context}\n",
    "\n",
    "---\n",
    "\"\"\"\n",
    "\n",
    "    # --- Task-specific logic ---\n",
    "    if is_derivation:\n",
    "        task_instructions = \"\"\"\n",
    "### Derivation Task:\n",
    "- Identify any equations or relationships relevant to the user query.\n",
    "- If equations are available, provide a **step-by-step derivation** in LaTeX.\n",
    "- Each step should be mathematically valid and based only on the paper.\n",
    "- Label steps clearly: Step 1, Step 2, etc.\n",
    "- If derivation context is missing, clearly say so.\n",
    "\n",
    "Output Format:\n",
    "[Slide 1]\n",
    "Title: Derivation Overview\n",
    "Bullets:\n",
    "- Purpose of derivation\n",
    "- Key starting equation\n",
    "Script:\n",
    "Explain the motivation.\n",
    "\n",
    "[Slide 2]\n",
    "Title: Step-by-Step Derivation\n",
    "Bullets:\n",
    "- Step 1 — ...\n",
    "- Step 2 — ...\n",
    "Script:\n",
    "Show equations and logic.\n",
    "\n",
    "[Slide 3]\n",
    "Title: Final Result\n",
    "Bullets:\n",
    "- Derived equation\n",
    "- Interpretation\n",
    "Script:\n",
    "Summarize result and relevance.\n",
    "\"\"\"\n",
    "    elif is_script:\n",
    "        task_instructions = \"\"\"\n",
    "### Technical Script Task:\n",
    "- Create 5–7 slides describing the paper’s mathematical or conceptual framework.\n",
    "- Each slide must include Title, Bullets, Speaker Notes, and a Script section.\n",
    "- Focus on clarity and flow.\n",
    "- Use LaTeX for math if present.\n",
    "- Keep explanations at an appropriate level for {audience} audiences.\n",
    "\"\"\"\n",
    "    else:\n",
    "        task_instructions = \"\"\"\n",
    "### Explanation Task:\n",
    "- Identify relevant parts of the context that explain the query topic.\n",
    "- Provide 1 concise slide with title, bullets, and a short explanatory script.\n",
    "- Keep language accessible for {audience}.\n",
    "\"\"\"\n",
    "\n",
    "    # --- Footer ---\n",
    "    footer = \"\"\"\n",
    "---\n",
    "\n",
    "### Query:\n",
    "{query}\n",
    "\n",
    "---\n",
    "\n",
    "Ensure:\n",
    "- All math uses LaTeX ($...$ or $$...$$).\n",
    "- Use only context provided from the paper.\n",
    "- Do NOT invent results not in the text.\n",
    "- If uncertain, say \"Not enough information in the paper.\"\n",
    "- Begin your answer directly with [Slide 1].\n",
    "\"\"\"\n",
    "\n",
    "    # --- 🔹 AUGMENTATION happens here ---\n",
    "    # Inject context, query, and audience into the template\n",
    "    augmented_prompt = (base_prompt + task_instructions + footer).format(\n",
    "        context=context, query=query, audience=audience\n",
    "    )\n",
    "\n",
    "    # --- Apply tokenizer chat template (Gemma-compatible) ---\n",
    "    dialogue = [{\"role\": \"user\", \"content\": augmented_prompt}]\n",
    "    prompt = tokenizer.apply_chat_template(\n",
    "        conversation=dialogue,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True\n",
    "    )\n",
    "\n",
    "    return prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Turn slide 5’s script into a short 3-bullet executive summary.\n",
      "\n",
      "--- Prompt Preview (first 1000 chars) ---\n",
      "\n",
      "<bos><start_of_turn>user\n",
      "You are SARAL, a research communication assistant that generates adaptive slide decks,\n",
      "scripts, and summaries from academic papers for general audiences.\n",
      "\n",
      "You will use only the context provided below to answer the query.\n",
      "If the paper does NOT contain enough information to answer, explicitly say:\n",
      "\"Not enough information in the paper to derive or explain this.\"\n",
      "\n",
      "---\n",
      "\n",
      "### Context (from paper):\n",
      "[Page 8] Figure 4: Under our ﬁrst derivation, a VDM can be optimized by ensuring that for every intermediate xt,the posterior from the latent above it pθ(xt|xt+1) matches the Gaussian corruption of the latent before itq(xt|xt−1). In this ﬁgure, for each intermediate xt, we minimize the diﬀerence between the distributionsrepresented by the pink and green arrows. Visually, this interpretation of the Evidence Lower Bound (ELBO) is depicted in Figure 4. The cost of optimizing a VDM is primarilydominated by the third term, since we must optimize over all timesteps t. Under this d\n",
      "\n",
      "-----------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Pick a random query\n",
    "query = random.choice(query_list)\n",
    "print(f\"Query: {query}\")\n",
    "\n",
    "# Retrieve relevant chunks directly from ChromaDB\n",
    "results = retrieve_relevant_chunks(query=query, top_k=5)\n",
    "\n",
    "# Build context items (each already has page_number and text)\n",
    "context_items = []\n",
    "for res in results:\n",
    "    context_items.append({\n",
    "        \"page_number\": res.get(\"page_number\", \"?\"),\n",
    "        \"sentence_chunk\": res[\"text\"]\n",
    "    })\n",
    "\n",
    "# Format the prompt using SARAL's math-aware, audience-adaptive template\n",
    "prompt = prompt_formatter(query=query, context_items=context_items)\n",
    "\n",
    "# Optional: Preview first 1000 characters of the prompt\n",
    "print(\"\\n--- Prompt Preview (first 1000 chars) ---\\n\")\n",
    "print(prompt[:1000])\n",
    "print(\"\\n-----------------------------------------\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SARAL Generated Output ===\n",
      "\n",
      "[Slide 1].\n",
      "model\n",
      "## [Slide 5] - Summary of Key Points\n",
      "\n",
      "**Title:** Key Components of the Evidence Lower Bound (ELBO) Derivation\n",
      "\n",
      "**Bullets:**\n",
      "\n",
      "- The ELBO is comprised of three main terms: reconstruction, prior matching, and denoising matching.\n",
      "- Each term is computed as an expectation of at most one random variable at a time, greatly reducing variance compared to the original ELBO derivation.\n",
      "- The Gaussian form of the approximated denoising transition step pθ(xt−1|xt) is derived and shown to match the ground-truth denoising transition step q(xt−1|xt, x_0) as closely as possible.\n"
     ]
    }
   ],
   "source": [
    "# --- Tokenize and move to GPU ---\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "# --- Generate output tokens ---\n",
    "with torch.no_grad():\n",
    "    outputs = llm_model.generate(\n",
    "        **inputs,\n",
    "        temperature=0.7,\n",
    "        do_sample=True,\n",
    "        max_new_tokens=512,\n",
    "        pad_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "\n",
    "# --- Decode and clean up ---\n",
    "output_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "# Ensure output starts from Slide section, not the prompt\n",
    "start_idx = output_text.find(\"[Slide 1]\")\n",
    "if start_idx != -1:\n",
    "    answer_only = output_text[start_idx:].strip()\n",
    "else:\n",
    "    answer_only = output_text.replace(prompt, \"\").strip()\n",
    "\n",
    "print(\"\\n=== SARAL Generated Output ===\\n\")\n",
    "print(answer_only)\n",
    "\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_saral_query(query: str, top_k: int = 5, show_prompt: bool = False, show_context: bool = False):\n",
    "    results = retrieve_relevant_chunks(query=query, top_k=top_k)\n",
    "\n",
    "    context_items = [\n",
    "        {\n",
    "            \"page_number\": res.get(\"page_number\", \"?\"),\n",
    "            \"contains_math\": res.get(\"contains_math\", False),\n",
    "            \"sentence_chunk\": res[\"text\"],\n",
    "        }\n",
    "        for res in results\n",
    "    ]\n",
    "\n",
    "    prompt = prompt_formatter(query=query, context_items=context_items)\n",
    "\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = llm_model.generate(\n",
    "            **inputs,\n",
    "            temperature=0.7,\n",
    "            do_sample=True,\n",
    "            max_new_tokens=1024,\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "        )\n",
    "\n",
    "    output_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    start_idx = output_text.find(\"[Slide 1]\")\n",
    "    if start_idx != -1:\n",
    "        answer_only = output_text[start_idx:].strip()\n",
    "    else:\n",
    "        answer_only = output_text.replace(prompt, \"\").strip()\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    return answer_only, context_items\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Query: Summarize the paper’s introduction and related work in a style suitable for policymakers unfamiliar with AI.\n",
      "\n",
      "\n",
      "=== Final Answer ===\n",
      "\n",
      "[Slide 1].\n",
      "model\n",
      "**[Slide 1]**\n",
      "\n",
      "**Summary of Introduction and Related Work**\n",
      "\n",
      "The paper introduces Variational Diffusion Models (VDMs), a novel generative model based on VAEs. VDM utilizes a Gaussian distribution to model the final latent representation and denoising transitions.\n",
      "\n",
      "**Related Work:**\n",
      "\n",
      "- Evidence Lower Bound (ELBO) is a key concept in VAEs that measures the evidence that a given model deviates from the true data distribution.\n",
      "- Variational Autoencoders (VAEs) are generative models that approximate the true data distribution by learning a latent representation.\n",
      "- Score-based Generative Models (SBGMs) estimate the score function of a model, which allows for sampling from the model's distribution.\n",
      "- Cascaded Diffusion Models (CDMs) generate high-fidelity images by iteratively denoising noisy images.\n",
      "\n",
      "**Conclusion:**\n",
      "\n",
      "The paper introduces VDM, a novel generative model that combines the advantages of VAEs and SBGMs. It utilizes a Gaussian distribution to model the final latent representation and denoising transitions, enabling efficient and accurate image generation.\n",
      "\n",
      "=== Context Chunks Used ===\n",
      "\n",
      "Page 0 (Math: False): Understanding Diﬀusion Models: A Uniﬁed PerspectiveCalvin LuoGoogle Research, Brain Teamcalvinluo@google.comAugust 26, 2022ContentsIntroduction: Gener...\n",
      "\n",
      "Page 22 (Math: True): References[1] Diederik P Kingma and Max Welling. Auto-encoding variational bayes.arXiv preprint arXiv:1312.6114, 2013.[2] Durk P Kingma, Tim Salimans,...\n",
      "\n",
      "Page 22 (Math: True): Advances in NeuralInformation Processing Systems, 33:6840–6851, 2020.[6] Diederik Kingma, Tim Salimans, Ben Poole, and Jonathan Ho. Variational diﬀusi...\n",
      "\n",
      "Page 22 (Math: True): Sliced score matching: A scalable approach to densityand score estimation. In Uncertainty in Artiﬁcial Intelligence, pages 574–584. PMLR, 2020.[17] Pa...\n",
      "\n",
      "Page 22 (Math: True): arXiv preprint arXiv:2011.13456, 2020.[11] Yang Song and Stefano Ermon. Improved techniques for training score-based generative models. Advances inneu...\n",
      "\n",
      "Page 7 (Math: True): Note that our encoder distributions q(xt|xt−1) are no longer parameterized by φ, as they are completelymodeled as Gaussians with deﬁned mean and varia...\n",
      "\n",
      "Page 9 (Math: True): = Eq(x_1:T |x_0)log p(xT )pθ(x_0|x_1)q(x_1|x_0)+ logTYt=2pθ(xt−1|xt)q(xt−1|xt,x_0)\u0018\u0018\u0018\u0018q(xt|x_0)(((((q(xt−1|x_0)(53)= Eq(x_1:T |x_0)\"log p(xT )pθ(x_0|x...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "query = random.choice(query_list)\n",
    "print(f\"\\n Query: {query}\\n\")\n",
    "\n",
    "answer, context_used = ask_saral_query(\n",
    "    query=query,\n",
    "    top_k=7,\n",
    "    show_prompt=True\n",
    ")\n",
    "\n",
    "print(\"\\n=== Final Answer ===\\n\")\n",
    "print(answer)\n",
    "print(\"\\n=== Context Chunks Used ===\\n\")\n",
    "for c in context_used:\n",
    "    print(f\"Page {c['page_number']} (Math: {c['contains_math']}): {c['sentence_chunk'][:150]}...\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_questions = [\n",
    "    \"What is the ELBO formula in a VAE?\",\n",
    "    \"How does the reparameterization trick help optimization?\",\n",
    "    \"What are the three terms of the ELBO in a Variational Diffusion Model?\",\n",
    "    \"Why is high T problematic for ELBO variance?\",\n",
    "    \"What is the goal of matching q(xt−1|xt, x₀) with pθ(xt−1|xt)?\"\n",
    "]\n",
    "\n",
    "ground_truth_answers = [\n",
    "    \"ELBO = E[log p(x|z)] - KL[q(z|x) || p(z)]\",\n",
    "    \"It rewrites stochastic sampling as a deterministic function, allowing gradients to flow through noise.\",\n",
    "    \"1. Reconstruction term, 2. Prior matching term, 3. Consistency or denoising term.\",\n",
    "    \"Higher T leads to more Monte Carlo estimations, increasing the variance in ELBO computation.\",\n",
    "    \"To learn a denoising step that approximates the true posterior distribution during sampling.\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "noise_robustness not available in this version\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import (\n",
    "    context_precision,\n",
    "    context_recall,\n",
    "    answer_relevancy,\n",
    "    faithfulness,\n",
    ")\n",
    "\n",
    "# Optional metrics\n",
    "try:\n",
    "    from ragas.metrics import context_entity_recall\n",
    "except ImportError:\n",
    "    context_entity_recall = None\n",
    "    print(\"context_entity_recall not available in this version\")\n",
    "\n",
    "try:\n",
    "    from ragas.metrics import noise_robustness\n",
    "except ImportError:\n",
    "    noise_robustness = None\n",
    "    print(\"noise_robustness not available in this version\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_questions = [\n",
    "    \"Derive the ELBO objective function step-by-step.\",\n",
    "    \"Summarize the key equation for the KL Divergence.\",\n",
    "    \"Explain how diffusion models relate to variational inference.\",\n",
    "    \"What is the role of the reparameterization trick in this paper?\",\n",
    "    \"State the loss function used for optimization.\"\n",
    "]\n",
    "\n",
    "ground_truth_answers = [\n",
    "    \"The ELBO is given by E_{q(z|x)}[log p(x|z)] - KL(q(z|x) || p(z)). The derivation involves applying Jensen's inequality to log p(x).\",\n",
    "    \"The KL Divergence measures the difference between q(z|x) and p(z) and is expressed as E_{q(z|x)}[log q(z|x) - log p(z)].\",\n",
    "    \"Diffusion models can be interpreted as hierarchical VAEs trained via a variational lower bound.\",\n",
    "    \"The reparameterization trick enables gradient flow through stochastic latent variables using z = μ + σϵ.\",\n",
    "    \"The loss function minimizes the KL divergence between the forward and reverse diffusion processes.\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_saral_answer(query):\n",
    "    \"\"\"Generate SARAL answer for RAG evaluation\"\"\"\n",
    "    # Retrieve relevant chunks\n",
    "    results = retrieve_relevant_chunks(query=query, top_k=5)\n",
    "\n",
    "    # Build context_items for prompt_formatter\n",
    "    context_items = [\n",
    "        {\n",
    "            \"page_number\": res.get(\"page_number\", \"?\"),\n",
    "            \"sentence_chunk\": res[\"text\"]\n",
    "        }\n",
    "        for res in results\n",
    "    ]\n",
    "\n",
    "    # Build the full prompt\n",
    "    prompt = prompt_formatter(query=query, context_items=context_items)\n",
    "\n",
    "    # Move prompt to device\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "    # Generate output\n",
    "    with torch.no_grad():\n",
    "        outputs = llm_model.generate(\n",
    "            **inputs,\n",
    "            temperature=0.7,\n",
    "            do_sample=True,\n",
    "            max_new_tokens=512,\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "        )\n",
    "\n",
    "    output_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    # Try to remove the prompt portion\n",
    "    start_idx = output_text.find(\"[Slide 1]\")\n",
    "    if start_idx != -1:\n",
    "        answer = output_text[start_idx:].strip()\n",
    "    else:\n",
    "        answer = output_text.replace(prompt, \"\").strip()\n",
    "\n",
    "    contexts = [item[\"sentence_chunk\"] for item in context_items]\n",
    "    return answer, contexts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating SARAL RAG answers for evaluation...\n",
      "\n",
      "Processing: Derive the ELBO objective function step-by-step....\n",
      "Processing: Summarize the key equation for the KL Divergence....\n",
      "Processing: Explain how diffusion models relate to variational inference...\n",
      "Processing: What is the role of the reparameterization trick in this pap...\n",
      "Processing: State the loss function used for optimization....\n"
     ]
    }
   ],
   "source": [
    "evaluation_data = []\n",
    "\n",
    "print(\"Generating SARAL RAG answers for evaluation...\\n\")\n",
    "for question, ground_truth in zip(eval_questions, ground_truth_answers):\n",
    "    print(f\"Processing: {question[:60]}...\")\n",
    "    rag_answer, contexts = generate_saral_answer(question)\n",
    "\n",
    "    evaluation_data.append({\n",
    "        'question': question,\n",
    "        'answer': rag_answer,\n",
    "        'contexts': contexts,\n",
    "        'ground_truth': ground_truth\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running RAGAS evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 25/25 [00:29<00:00,  1.19s/it]\n"
     ]
    }
   ],
   "source": [
    "eval_dataset = Dataset.from_pandas(pd.DataFrame(evaluation_data))\n",
    "\n",
    "metrics = [\n",
    "    context_precision,\n",
    "    context_recall,\n",
    "    answer_relevancy,\n",
    "    faithfulness\n",
    "]\n",
    "\n",
    "if context_entity_recall is not None:\n",
    "    metrics.append(context_entity_recall)\n",
    "if noise_robustness is not None:\n",
    "    metrics.append(noise_robustness)\n",
    "\n",
    "print(\"\\nRunning RAGAS evaluation...\")\n",
    "results = evaluate(\n",
    "    dataset=eval_dataset,\n",
    "    metrics=metrics,\n",
    ")\n",
    "results_df = results.to_pandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      " SARAL RAG EVALUATION RESULTS\n",
      "================================================================================\n",
      "\n",
      "📋 INDIVIDUAL QUESTION PERFORMANCE\n",
      "--------------------------------------------------------------------------------\n",
      "                                                 Question  Context Precision  Context Recall  Answer Relevancy  Faithfulness  Context Entity Recall\n",
      "  Q1: Derive the ELBO objective function step-by-step....              1.000             1.0             0.954         0.800                  0.200\n",
      " Q2: Summarize the key equation for the KL Divergence....              0.250             1.0             0.000         0.125                  0.250\n",
      "Q3: Explain how diffusion models relate to variational...              1.000             1.0             0.956         0.778                  0.000\n",
      "Q4: What is the role of the reparameterization trick i...              1.000             1.0             0.961         1.000                  0.167\n",
      "    Q5: State the loss function used for optimization....              0.639             1.0             0.858         1.000                  0.000\n",
      "\n",
      "📊 OVERALL AVERAGE SCORES\n",
      "--------------------------------------------------\n",
      "Context Precision        : 0.778\n",
      "Context Recall           : 1.000\n",
      "Answer Relevancy         : 0.746\n",
      "Faithfulness             : 0.741\n",
      "Context Entity Recall    : 0.123\n",
      "\n",
      "💾 Results saved to 'saral_rag_evaluation.csv'\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\" SARAL RAG EVALUATION RESULTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Collect numeric columns\n",
    "metric_cols = [c for c in results_df.columns if c not in ['user_input', 'retrieved_contexts', 'response', 'reference']]\n",
    "\n",
    "# Clean result table\n",
    "clean_results = pd.DataFrame()\n",
    "clean_results['Question'] = [f\"Q{i+1}: {q[:50]}...\" for i, q in enumerate(results_df['user_input'])]\n",
    "for col in metric_cols:\n",
    "    clean_results[col.replace('_', ' ').title()] = results_df[col].round(3)\n",
    "\n",
    "print(\"\\n📋 INDIVIDUAL QUESTION PERFORMANCE\")\n",
    "print(\"-\"*80)\n",
    "print(clean_results.to_string(index=False))\n",
    "\n",
    "# Overall averages\n",
    "print(\"\\n📊 OVERALL AVERAGE SCORES\")\n",
    "print(\"-\"*50)\n",
    "for col in metric_cols:\n",
    "    avg = results_df[col].mean()\n",
    "    print(f\"{col.replace('_', ' ').title():<25}: {avg:.3f}\")\n",
    "\n",
    "# Save to CSV\n",
    "detailed_results = pd.DataFrame(evaluation_data)\n",
    "for col in metric_cols:\n",
    "    detailed_results[col] = results_df[col].values\n",
    "detailed_results.to_csv('saral_rag_evaluation.csv', index=False)\n",
    "\n",
    "print(\"\\n💾 Results saved to 'saral_rag_evaluation.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 Best metric: context_recall\n",
      "⚠️ Weakest metric: context_entity_recall\n"
     ]
    }
   ],
   "source": [
    "best_metric = max(metric_cols, key=lambda c: results_df[c].mean())\n",
    "worst_metric = min(metric_cols, key=lambda c: results_df[c].mean())\n",
    "\n",
    "print(f\"\\n🚀 Best metric: {best_metric}\")\n",
    "print(f\"⚠️ Weakest metric: {worst_metric}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'ErrorWrapper' from 'fastapi._compat' (/media/data_dump/conda/miniconda3/envs/SARAL/lib/python3.10/site-packages/fastapi/_compat/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#!pip install gradio\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgradio\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgr\u001b[39;00m\n",
      "File \u001b[0;32m/media/data_dump/conda/miniconda3/envs/SARAL/lib/python3.10/site-packages/gradio/__init__.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgradio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_simple_templates\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgradio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage_utils\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgradio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprocessing_utils\u001b[39;00m\n",
      "File \u001b[0;32m/media/data_dump/conda/miniconda3/envs/SARAL/lib/python3.10/site-packages/gradio/_simple_templates/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msimpledropdown\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SimpleDropdown\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msimpleimage\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SimpleImage\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msimpletextbox\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SimpleTextbox\n",
      "File \u001b[0;32m/media/data_dump/conda/miniconda3/envs/SARAL/lib/python3.10/site-packages/gradio/_simple_templates/simpledropdown.py:7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcollections\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mabc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Callable, Sequence\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TYPE_CHECKING, Any, Literal\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgradio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcomponents\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Component, FormComponent\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgradio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mevents\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Events\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgradio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mi18n\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m I18nData\n",
      "File \u001b[0;32m/media/data_dump/conda/miniconda3/envs/SARAL/lib/python3.10/site-packages/gradio/components/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgradio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcomponents\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mannotated_image\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AnnotatedImage\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgradio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcomponents\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maudio\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Audio\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgradio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcomponents\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      4\u001b[0m     Component,\n\u001b[1;32m      5\u001b[0m     FormComponent,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m     get_component_instance,\n\u001b[1;32m     11\u001b[0m )\n",
      "File \u001b[0;32m/media/data_dump/conda/miniconda3/envs/SARAL/lib/python3.10/site-packages/gradio/components/annotated_image.py:14\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgradio_client\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m handle_file\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgradio_client\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdocumentation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m document\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgradio\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m processing_utils, utils\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgradio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcomponents\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Component\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgradio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_classes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FileData, GradioModel\n",
      "File \u001b[0;32m/media/data_dump/conda/miniconda3/envs/SARAL/lib/python3.10/site-packages/gradio/processing_utils.py:29\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgradio_client\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m utils \u001b[38;5;28;01mas\u001b[39;00m client_utils\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mPIL\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Image, ImageOps, ImageSequence, PngImagePlugin\n\u001b[0;32m---> 29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgradio\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m utils\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgradio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcontext\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LocalContext\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgradio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_classes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FileData, GradioModel, GradioRootModel, JsonData\n",
      "File \u001b[0;32m/media/data_dump/conda/miniconda3/envs/SARAL/lib/python3.10/site-packages/gradio/utils.py:68\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgradio\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgradio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcontext\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_blocks_context\n\u001b[0;32m---> 68\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgradio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_classes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     69\u001b[0m     BlocksConfigDict,\n\u001b[1;32m     70\u001b[0m     DeveloperPath,\n\u001b[1;32m     71\u001b[0m     FileData,\n\u001b[1;32m     72\u001b[0m     UserProvidedPath,\n\u001b[1;32m     73\u001b[0m )\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgradio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Error, InvalidPathError\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:  \u001b[38;5;66;03m# Only import for type checking (is False at runtime).\u001b[39;00m\n",
      "File \u001b[0;32m/media/data_dump/conda/miniconda3/envs/SARAL/lib/python3.10/site-packages/gradio/data_classes.py:20\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01menum\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Enum, auto\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     13\u001b[0m     Annotated,\n\u001b[1;32m     14\u001b[0m     Any,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     17\u001b[0m     Union,\n\u001b[1;32m     18\u001b[0m )\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mfastapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Request\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgradio_client\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_classes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ParameterInfo\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgradio_client\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdocumentation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m document\n",
      "File \u001b[0;32m/media/data_dump/conda/miniconda3/envs/SARAL/lib/python3.10/site-packages/fastapi/__init__.py:7\u001b[0m\n\u001b[1;32m      3\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0.115.6\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mstarlette\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m status \u001b[38;5;28;01mas\u001b[39;00m status\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapplications\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FastAPI \u001b[38;5;28;01mas\u001b[39;00m FastAPI\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackground\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BackgroundTasks \u001b[38;5;28;01mas\u001b[39;00m BackgroundTasks\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatastructures\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m UploadFile \u001b[38;5;28;01mas\u001b[39;00m UploadFile\n",
      "File \u001b[0;32m/media/data_dump/conda/miniconda3/envs/SARAL/lib/python3.10/site-packages/fastapi/applications.py:16\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01menum\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Enum\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      3\u001b[0m     Any,\n\u001b[1;32m      4\u001b[0m     Awaitable,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m     Union,\n\u001b[1;32m     14\u001b[0m )\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mfastapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m routing\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mfastapi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatastructures\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Default, DefaultPlaceholder\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mfastapi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexception_handlers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     19\u001b[0m     http_exception_handler,\n\u001b[1;32m     20\u001b[0m     request_validation_exception_handler,\n\u001b[1;32m     21\u001b[0m     websocket_request_validation_exception_handler,\n\u001b[1;32m     22\u001b[0m )\n",
      "File \u001b[0;32m/media/data_dump/conda/miniconda3/envs/SARAL/lib/python3.10/site-packages/fastapi/routing.py:35\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mfastapi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatastructures\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Default, DefaultPlaceholder\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mfastapi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdependencies\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dependant\n\u001b[0;32m---> 35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mfastapi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdependencies\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     36\u001b[0m     _should_embed_body_fields,\n\u001b[1;32m     37\u001b[0m     get_body_field,\n\u001b[1;32m     38\u001b[0m     get_dependant,\n\u001b[1;32m     39\u001b[0m     get_flat_dependant,\n\u001b[1;32m     40\u001b[0m     get_parameterless_sub_dependant,\n\u001b[1;32m     41\u001b[0m     get_typed_return_annotation,\n\u001b[1;32m     42\u001b[0m     solve_dependencies,\n\u001b[1;32m     43\u001b[0m )\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mfastapi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mencoders\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m jsonable_encoder\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mfastapi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     46\u001b[0m     FastAPIError,\n\u001b[1;32m     47\u001b[0m     RequestValidationError,\n\u001b[1;32m     48\u001b[0m     ResponseValidationError,\n\u001b[1;32m     49\u001b[0m     WebSocketRequestValidationError,\n\u001b[1;32m     50\u001b[0m )\n",
      "File \u001b[0;32m/media/data_dump/conda/miniconda3/envs/SARAL/lib/python3.10/site-packages/fastapi/dependencies/utils.py:23\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01manyio\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mfastapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m params\n\u001b[0;32m---> 23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mfastapi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_compat\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     24\u001b[0m     PYDANTIC_V2,\n\u001b[1;32m     25\u001b[0m     ErrorWrapper,\n\u001b[1;32m     26\u001b[0m     ModelField,\n\u001b[1;32m     27\u001b[0m     RequiredParam,\n\u001b[1;32m     28\u001b[0m     Undefined,\n\u001b[1;32m     29\u001b[0m     _regenerate_error_with_loc,\n\u001b[1;32m     30\u001b[0m     copy_field_info,\n\u001b[1;32m     31\u001b[0m     create_body_model,\n\u001b[1;32m     32\u001b[0m     evaluate_forwardref,\n\u001b[1;32m     33\u001b[0m     field_annotation_is_scalar,\n\u001b[1;32m     34\u001b[0m     get_annotation_from_field_info,\n\u001b[1;32m     35\u001b[0m     get_cached_model_fields,\n\u001b[1;32m     36\u001b[0m     get_missing_field_error,\n\u001b[1;32m     37\u001b[0m     is_bytes_field,\n\u001b[1;32m     38\u001b[0m     is_bytes_sequence_field,\n\u001b[1;32m     39\u001b[0m     is_scalar_field,\n\u001b[1;32m     40\u001b[0m     is_scalar_sequence_field,\n\u001b[1;32m     41\u001b[0m     is_sequence_field,\n\u001b[1;32m     42\u001b[0m     is_uploadfile_or_nonable_uploadfile_annotation,\n\u001b[1;32m     43\u001b[0m     is_uploadfile_sequence_annotation,\n\u001b[1;32m     44\u001b[0m     lenient_issubclass,\n\u001b[1;32m     45\u001b[0m     sequence_types,\n\u001b[1;32m     46\u001b[0m     serialize_sequence_value,\n\u001b[1;32m     47\u001b[0m     value_is_sequence,\n\u001b[1;32m     48\u001b[0m )\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mfastapi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackground\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BackgroundTasks\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mfastapi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconcurrency\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     51\u001b[0m     asynccontextmanager,\n\u001b[1;32m     52\u001b[0m     contextmanager_in_threadpool,\n\u001b[1;32m     53\u001b[0m )\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'ErrorWrapper' from 'fastapi._compat' (/media/data_dump/conda/miniconda3/envs/SARAL/lib/python3.10/site-packages/fastapi/_compat/__init__.py)"
     ]
    }
   ],
   "source": [
    "#!pip install gradio\n",
    "import gradio as gr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saral_chat_interface(query, top_k=5, audience=\"general\"):\n",
    "    \"\"\"\n",
    "    Gradio interface function for SARAL chatbot.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        answer, context_used = ask_saral_query(query=query, top_k=top_k, show_prompt=False)\n",
    "        context_str = \"\\n\\n\".join([f\"📄 Page {c['page_number']}: {c['sentence_chunk'][:300]}...\" for c in context_used])\n",
    "        return answer, context_str\n",
    "    except Exception as e:\n",
    "        return f\"⚠️ Error: {str(e)}\", \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_pdf(file_obj):\n",
    "    \"\"\"\n",
    "    Called when a new PDF is uploaded.\n",
    "    Extracts text, chunks it, creates embeddings, and stores in Chroma.\n",
    "    \"\"\"\n",
    "    import fitz\n",
    "    import re\n",
    "    from tqdm.auto import tqdm\n",
    "\n",
    "    pdf_path = file_obj.name\n",
    "    doc = fitz.open(pdf_path)\n",
    "\n",
    "    pages_and_texts = []\n",
    "    for page_number, page in tqdm(enumerate(doc)):\n",
    "        text = page.get_text()\n",
    "        text = text.replace(\"\\n\", \" \").strip()\n",
    "        pages_and_texts.append({\n",
    "            \"page_number\": page_number,\n",
    "            \"text\": text,\n",
    "        })\n",
    "\n",
    "    # Chunk + embed + store in Chroma (reusing your existing functions)\n",
    "    # For simplicity, you can call your existing embedding code here\n",
    "    # Example:\n",
    "    # rebuild_chromadb_from_pdf(pages_and_texts)\n",
    "\n",
    "    return f\"✅ Uploaded and processed {len(pages_and_texts)} pages from: {pdf_path}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gr.Blocks(theme=gr.themes.Soft()) as saral_ui:\n",
    "    gr.Markdown(\n",
    "        \"\"\"\n",
    "        # 🧠 SARAL — Audience-Adaptive Research Communicator  \n",
    "        Upload a paper or ask a question to generate scripts, slides, or summaries.\n",
    "        ---\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    with gr.Tab(\"Chat with SARAL\"):\n",
    "        with gr.Row():\n",
    "            query_box = gr.Textbox(\n",
    "                label=\"Enter your request\",\n",
    "                placeholder=\"e.g., Make a 5-slide talk for graduate students focusing on methods...\",\n",
    "                lines=3\n",
    "            )\n",
    "\n",
    "        with gr.Row():\n",
    "            audience_box = gr.Dropdown(\n",
    "                [\"general\", \"technical\", \"policymaker\", \"press release\", \"student\"],\n",
    "                value=\"general\",\n",
    "                label=\"Target Audience\"\n",
    "            )\n",
    "            topk_slider = gr.Slider(3, 10, value=5, step=1, label=\"Top-k Chunks Retrieved\")\n",
    "\n",
    "        with gr.Row():\n",
    "            answer_box = gr.Textbox(label=\"SARAL Response\", lines=20)\n",
    "            context_box = gr.Textbox(label=\"Retrieved Context (Provenance)\", lines=20)\n",
    "\n",
    "        submit_btn = gr.Button(\"💬 Generate\")\n",
    "\n",
    "        submit_btn.click(\n",
    "            fn=saral_chat_interface,\n",
    "            inputs=[query_box, topk_slider, audience_box],\n",
    "            outputs=[answer_box, context_box]\n",
    "        )\n",
    "\n",
    "    with gr.Tab(\"Upload Paper\"):\n",
    "        pdf_input = gr.File(label=\"Upload PDF Paper\")\n",
    "        upload_output = gr.Textbox(label=\"Upload Status\")\n",
    "        pdf_input.upload(process_pdf, inputs=pdf_input, outputs=upload_output)\n",
    "\n",
    "    gr.Markdown(\"Built with ❤️ using Gemma + Chroma + Gradio\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* Running on public URL: https://70824d6061c571da85.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://70824d6061c571da85.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:    Exception in ASGI application\n",
      "Traceback (most recent call last):\n",
      "  File \"/media/data_dump/conda/miniconda3/envs/SARAL/lib/python3.10/site-packages/uvicorn/protocols/http/httptools_impl.py\", line 409, in run_asgi\n",
      "    result = await app(  # type: ignore[func-returns-value]\n",
      "  File \"/media/data_dump/conda/miniconda3/envs/SARAL/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py\", line 60, in __call__\n",
      "    return await self.app(scope, receive, send)\n",
      "  File \"/media/data_dump/conda/miniconda3/envs/SARAL/lib/python3.10/site-packages/fastapi/applications.py\", line 1134, in __call__\n",
      "    response_model_exclude_defaults: bool = False,\n",
      "  File \"/media/data_dump/conda/miniconda3/envs/SARAL/lib/python3.10/site-packages/starlette/applications.py\", line 113, in __call__\n",
      "    await self.middleware_stack(scope, receive, send)\n",
      "  File \"/media/data_dump/conda/miniconda3/envs/SARAL/lib/python3.10/site-packages/starlette/middleware/errors.py\", line 186, in __call__\n",
      "    # to optionally raise the error within the test case.\n",
      "  File \"/media/data_dump/conda/miniconda3/envs/SARAL/lib/python3.10/site-packages/starlette/middleware/errors.py\", line 164, in __call__\n",
      "    try:\n",
      "  File \"/media/data_dump/conda/miniconda3/envs/SARAL/lib/python3.10/site-packages/gradio/brotli_middleware.py\", line 74, in __call__\n",
      "    return await self.app(scope, receive, send)\n",
      "  File \"/media/data_dump/conda/miniconda3/envs/SARAL/lib/python3.10/site-packages/gradio/route_utils.py\", line 888, in __call__\n",
      "    await self.simple_response(scope, receive, send, request_headers=headers)\n",
      "  File \"/media/data_dump/conda/miniconda3/envs/SARAL/lib/python3.10/site-packages/gradio/route_utils.py\", line 904, in simple_response\n",
      "    await self.app(scope, receive, send)\n",
      "  File \"/media/data_dump/conda/miniconda3/envs/SARAL/lib/python3.10/site-packages/starlette/middleware/exceptions.py\", line 63, in __call__\n",
      "  File \"/media/data_dump/conda/miniconda3/envs/SARAL/lib/python3.10/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n",
      "    raise exc\n",
      "  File \"/media/data_dump/conda/miniconda3/envs/SARAL/lib/python3.10/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n",
      "    await app(scope, receive, sender)\n",
      "  File \"/media/data_dump/conda/miniconda3/envs/SARAL/lib/python3.10/site-packages/fastapi/middleware/asyncexitstack.py\", line 18, in __call__\n",
      "    await self.app(scope, receive, send)\n",
      "  File \"/media/data_dump/conda/miniconda3/envs/SARAL/lib/python3.10/site-packages/starlette/routing.py\", line 716, in __call__\n",
      "  File \"/media/data_dump/conda/miniconda3/envs/SARAL/lib/python3.10/site-packages/starlette/routing.py\", line 736, in app\n",
      "    return\n",
      "  File \"/media/data_dump/conda/miniconda3/envs/SARAL/lib/python3.10/site-packages/starlette/routing.py\", line 290, in handle\n",
      "    def __eq__(self, other: typing.Any) -> bool:\n",
      "  File \"/media/data_dump/conda/miniconda3/envs/SARAL/lib/python3.10/site-packages/fastapi/routing.py\", line 125, in app\n",
      "  File \"/media/data_dump/conda/miniconda3/envs/SARAL/lib/python3.10/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n",
      "    raise exc\n",
      "  File \"/media/data_dump/conda/miniconda3/envs/SARAL/lib/python3.10/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n",
      "    await app(scope, receive, sender)\n",
      "  File \"/media/data_dump/conda/miniconda3/envs/SARAL/lib/python3.10/site-packages/fastapi/routing.py\", line 111, in app\n",
      "    elif isinstance(res, dict):\n",
      "  File \"/media/data_dump/conda/miniconda3/envs/SARAL/lib/python3.10/site-packages/fastapi/routing.py\", line 391, in app\n",
      "    path: str,\n",
      "  File \"/media/data_dump/conda/miniconda3/envs/SARAL/lib/python3.10/site-packages/fastapi/routing.py\", line 290, in run_endpoint_function\n",
      "    async with AsyncExitStack() as async_exit_stack:\n",
      "  File \"/media/data_dump/conda/miniconda3/envs/SARAL/lib/python3.10/site-packages/gradio/routes.py\", line 1726, in upload_file\n",
      "    directory.mkdir(exist_ok=True, parents=True)\n",
      "  File \"/media/data_dump/conda/miniconda3/envs/SARAL/lib/python3.10/pathlib.py\", line 1175, in mkdir\n",
      "    self._accessor.mkdir(self, mode)\n",
      "PermissionError: [Errno 13] Permission denied: '/tmp/gradio/7baa99a649eb08ead2cb4c94ab90f6af7fe74ed02d4d3f6bb3a63bcbe4564af9'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyboard interruption in main thread... closing server.\n",
      "Killing tunnel 127.0.0.1:7860 <> https://70824d6061c571da85.gradio.live\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saral_ui.launch(share=True, debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SARAL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
